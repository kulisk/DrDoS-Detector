"""
DDoS Detection System - Î”Î¹Î±Î¼Î¿ÏÏ†ÏÏƒÎ¹Î¼Î¿ Script
=============================================

Î‘Ï…Ï„ÏŒ Ï„Î¿ script Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Ï€Î»Î®ÏÎ· Î­Î»ÎµÎ³Ï‡Î¿ Ï„Î·Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ DDoS Î¼Î­ÏƒÏ‰ Î¼ÎµÏ„Î±Î²Î»Î·Ï„ÏÎ½ Î´Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ·Ï‚.
Î¡Ï…Î¸Î¼Î¯ÏƒÏ„Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ ÏƒÏ„Î·Î½ ÎµÎ½ÏŒÏ„Î·Ï„Î± CONFIGURATION ÎºÎ±Î¹ ÎµÎºÏ„ÎµÎ»Î­ÏƒÏ„Îµ Ï„Î¿ script.

Î”Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚:
- Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
- ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (on/off)
- Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE Î³Î¹Î± Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± ÎºÎ»Î¬ÏƒÎµÏ‰Î½ (on/off)
- Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Logistic Regression
- Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÎºÎ±Î¹ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
- Î‘Î½Î¬Î»Ï…ÏƒÎ· ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
- Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÎºÎ±Î¹ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
import warnings
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report, 
    confusion_matrix, 
    accuracy_score,
    precision_score, 
    recall_score, 
    f1_score,
    roc_curve,
    auc
)

warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION - ÎœÎ•Î¤Î‘Î’Î›Î—Î¤Î•Î£ Î”Î™Î‘ÎœÎŸÎ¡Î¦Î©Î£Î—Î£
# ============================================================================

class Config:
    """ÎšÎ»Î¬ÏƒÎ· Î´Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î¿ DDoS Detection System"""
    
    # --- Î‘Î¡Î§Î•Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î ---
    CSV_FILE = 'DrDoS_DNS.csv'                    # Î‘ÏÏ‡ÎµÎ¯Î¿ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï… CSV
    
    # --- Î¦Î‘ÎšÎ•Î›ÎŸÎ™ Î•ÎÎŸÎ”ÎŸÎ¥ ---
    RESULTS_DIR = 'results'                       # Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î³Î¹Î± Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
    MODEL_DIR = 'trained_model'                   # Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î³Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    
    # --- Î§Î©Î¡Î™Î£ÎœÎŸÎ£ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î ---
    TEST_SIZE = 0.3                               # Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± test (0.3 = 30%)
    RANDOM_STATE = 42                             # Seed Î³Î¹Î± reproducibility
    
    # --- SMOTE Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ ---
    USE_SMOTE = True                              # True: Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE, False: Î§Ï‰ÏÎ¯Ï‚ SMOTE
    SMOTE_SAMPLING_STRATEGY = 1.0                 # 1.0 = 50-50 Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±, 0.5 = 1:2, ÎºÎ»Ï€
    SMOTE_K_NEIGHBORS = 5                         # Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³ÎµÎ¹Ï„ÏŒÎ½Ï‰Î½ Î³Î¹Î± SMOTE
    
    # --- ÎœÎŸÎÎ¤Î•Î›ÎŸ ---
    MODEL_MAX_ITER = 1000                         # ÎœÎ­Î³Î¹ÏƒÏ„ÎµÏ‚ ÎµÏ€Î±Î½Î±Î»Î®ÏˆÎµÎ¹Ï‚ Î³Î¹Î± Logistic Regression
    MODEL_VERBOSE = 0                             # 0: Î§Ï‰ÏÎ¯Ï‚ output, 1: ÎœÎµ progress
    
    # --- ÎŸÎ Î¤Î™ÎšÎŸÎ ÎŸÎ™Î—Î£Î•Î™Î£ ---
    ENABLE_VISUALIZATIONS = True                  # True: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½, False: ÎŒÏ‡Î¹
    PLOT_CORRELATION_MATRIX = True                # Î§Î¬ÏÏ„Î·Ï‚ ÏƒÏ…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚
    PLOT_CLASS_DISTRIBUTION = True                # Pie chart ÎºÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚ ÎºÎ»Î¬ÏƒÎµÏ‰Î½
    PLOT_FEATURE_DISTRIBUTIONS = True             # Box plots Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
    PLOT_SMOTE_COMPARISON = True                  # Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Ï€ÏÎ¹Î½/Î¼ÎµÏ„Î¬ SMOTE
    PLOT_CONFUSION_MATRIX = True                  # Confusion Matrix
    PLOT_ROC_CURVE = True                         # ROC Curve
    PLOT_FEATURE_IMPORTANCE = True                # Î£Î·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
    
    # --- Î‘Î ÎŸÎ˜Î—ÎšÎ•Î¥Î£Î— Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î ---
    SAVE_MODEL = True                             # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    SAVE_METRICS_CSV = True                       # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ ÏƒÎµ CSV
    SAVE_FEATURE_IMPORTANCE_CSV = True            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
    
    # --- Î‘ÎÎ‘Î¦ÎŸÎ¡Î•Î£ ---
    PRINT_DETAILED_REPORT = True                  # Î›ÎµÏ€Ï„Î¿Î¼ÎµÏÎ®Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬ ÏƒÏ„Î·Î½ ÎºÎ¿Î½ÏƒÏŒÎ»Î±
    PRINT_CLASSIFICATION_REPORT = True            # Classification report
    PRINT_FEATURE_IMPORTANCE_TOP_N = 15           # Î ÏŒÏƒÎ± top features Î½Î± ÎµÎ¼Ï†Î±Î½Î¹ÏƒÏ„Î¿ÏÎ½
    
    # --- Î“Î¡Î‘Î¦Î—ÎœÎ‘Î¤Î‘ ---
    FIGURE_DPI = 150                              # DPI Î³Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎµÎ¹ÎºÏŒÎ½Ï‰Î½
    FIGURE_FORMAT = 'png'                         # ÎœÎ¿ÏÏ†Î® Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚ (png, jpg, pdf)
    
    # --- Î Î¡ÎŸÎ§Î©Î¡Î—ÎœÎ•ÎÎ•Î£ Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ ---
    HANDLE_INFINITY = True                        # Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· inf Ï„Î¹Î¼ÏÎ½
    HANDLE_NAN = True                             # Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· NaN Ï„Î¹Î¼ÏÎ½
    STRATIFY_SPLIT = True                         # Stratified split Î³Î¹Î± train/test
    
    # --- TOP FEATURES Î“Î™Î‘ BOX PLOTS ---
    TOP_FEATURES_FOR_PLOTS = [
        ' Source Port', 
        ' Protocol', 
        ' Flow Duration',
        ' Total Fwd Packets', 
        ' Total Length of Bwd Packets'
    ]

# ============================================================================
# Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ•Î£ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î•Î™Î£
# ============================================================================

def print_header(title, char="="):
    """Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· ÏŒÎ¼Î¿ÏÏ†Î¿Ï… header"""
    print(f"\n{char*70}")
    print(f" {title}")
    print(f"{char*70}\n")

def print_section(title):
    """Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Ï„Î¯Ï„Î»Î¿Ï… section"""
    print(f"\n{'='*70}")
    print(f"{title}")
    print(f"{'='*70}\n")

def save_figure(fig, filename, dpi=None):
    """Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚"""
    if not Config.ENABLE_VISUALIZATIONS:
        plt.close(fig)
        return
        
    if not os.path.exists(Config.RESULTS_DIR):
        os.makedirs(Config.RESULTS_DIR)
    
    dpi = dpi or Config.FIGURE_DPI
    filepath = os.path.join(Config.RESULTS_DIR, f"{filename}.{Config.FIGURE_FORMAT}")
    fig.savefig(filepath, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    
    if Config.PRINT_DETAILED_REPORT:
        print(f"âœ“ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ: {filepath}")

def ensure_dir(directory):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï†Î±ÎºÎ­Î»Î¿Ï… Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹"""
    if not os.path.exists(directory):
        os.makedirs(directory)

# ============================================================================
# 1. Î¦ÎŸÎ¡Î¤Î©Î£Î— ÎšÎ‘Î™ Î Î¡ÎŸÎ•Î Î•ÎÎ•Î¡Î“Î‘Î£Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î
# ============================================================================

def load_and_preprocess_data():
    """
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    
    Returns:
        X: Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
        y: Labels
        feature_names: ÎŸÎ½ÏŒÎ¼Î±Ï„Î± Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
        df: Original dataframe
    """
    print_section("Î¦ÎŸÎ¡Î¤Î©Î£Î— ÎšÎ‘Î™ Î Î¡ÎŸÎ•Î Î•ÎÎ•Î¡Î“Î‘Î£Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    print(f"ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ '{Config.CSV_FILE}'...")
    if not os.path.exists(Config.CSV_FILE):
        raise FileNotFoundError(f"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ {Config.CSV_FILE} Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ!")
    
    df = pd.read_csv(Config.CSV_FILE)
    print(f"âœ“ Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(df):,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚")
    
    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î· ÏƒÏ„Î®Î»Î· Label
    if ' Label' not in df.columns:
        raise ValueError("Î— ÏƒÏ„Î®Î»Î· ' Label' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ„Î¿ dataset!")
    
    # Î•Ï€Î¹Î»Î¿Î³Î® Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
    print("\nğŸ” Î•Ï€Î¹Î»Î¿Î³Î® Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½...")
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns
    features = [col for col in numeric_features if col != ' Label']
    X = df[features]
    y = df[' Label']
    
    print(f"âœ“ Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ {len(features)} Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¬ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬")
    
    if Config.PRINT_DETAILED_REPORT:
        print(f"\nğŸ“Š Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Dataset:")
        print(f"   - Î•Î³Î³ÏÎ±Ï†Î­Ï‚: {X.shape[0]:,}")
        print(f"   - Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬: {X.shape[1]}")
    
    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    if Config.HANDLE_INFINITY or Config.HANDLE_NAN:
        print("\nğŸ”„ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
        original_len = len(X)
        
        if Config.HANDLE_INFINITY:
            X = X.replace([np.inf, -np.inf], np.nan)
        
        if Config.HANDLE_NAN:
            mask = X.notna().all(axis=1)
            X = X[mask]
            y = y[mask]
            df = df[mask].reset_index(drop=True)
            removed_rows = original_len - len(X)
            print(f"âœ“ Î‘Ï†Î±Î¹ÏÎ­Î¸Î·ÎºÎ±Î½ {removed_rows:,} Î³ÏÎ±Î¼Î¼Î­Ï‚ Î¼Îµ ÎµÎ»Î»Î¹Ï€ÎµÎ¯Ï‚ Ï„Î¹Î¼Î­Ï‚")
    
    print(f"âœ“ Î¤ÎµÎ»Î¹ÎºÏŒ Î¼Î­Î³ÎµÎ¸Î¿Ï‚: {len(X):,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚")
    
    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® labels ÏƒÎµ binary
    y = (y == 'DrDoS_DNS').astype(int)
    
    # ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½
    if Config.PRINT_DETAILED_REPORT:
        value_counts = y.value_counts()
        print("\nğŸ“ˆ ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½ (Î‘ÏÏ‡Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±):")
        for label, count in value_counts.items():
            percentage = count / len(y) * 100
            class_name = 'Attack (DrDoS_DNS)' if label == 1 else 'Normal Traffic'
            print(f"   - {class_name}: {count:,} ({percentage:.2f}%)")
    
    return X, y, X.columns.tolist(), df

# ============================================================================
# 2. ÎŸÎ Î¤Î™ÎšÎŸÎ ÎŸÎ™Î—Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î
# ============================================================================

def visualize_data(X, y, df):
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"""
    if not Config.ENABLE_VISUALIZATIONS:
        return
    
    print_section("ÎŸÎ Î¤Î™ÎšÎŸÎ ÎŸÎ™Î—Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    ensure_dir(Config.RESULTS_DIR)
    
    # 1. Î§Î¬ÏÏ„Î·Ï‚ ÏƒÏ…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚
    if Config.PLOT_CORRELATION_MATRIX:
        print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï‡Î¬ÏÏ„Î· ÏƒÏ…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚...")
        fig, ax = plt.subplots(figsize=(20, 16))
        correlation_matrix = X.corr()
        sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, ax=ax)
        ax.set_title('Î§Î¬ÏÏ„Î·Ï‚ Î£Ï…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½', fontsize=16, fontweight='bold')
        save_figure(fig, 'correlation_matrix')
    
    # 2. ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½
    if Config.PLOT_CLASS_DISTRIBUTION:
        print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± pie chart ÎºÎ»Î¬ÏƒÎµÏ‰Î½...")
        fig, ax = plt.subplots(figsize=(10, 8))
        value_counts = y.value_counts()
        attack_count = value_counts.get(1, 0)
        normal_count = value_counts.get(0, 0)
        
        sizes = [attack_count, normal_count]
        labels_pie = ['Attack (DrDoS_DNS)', 'Normal Traffic']
        colors = ['#ff9999', '#66b3ff']
        
        ax.pie(sizes, labels=labels_pie, autopct='%1.1f%%', colors=colors, 
               startangle=90, textprops={'fontsize': 14})
        ax.set_title('ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎšÎ»Î¬ÏƒÎµÏ‰Î½ (Î ÏÎ¹Î½ SMOTE)', fontsize=16, fontweight='bold')
        save_figure(fig, 'class_distribution_before_smote')
    
    # 3. Box plots Î³Î¹Î± top Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
    if Config.PLOT_FEATURE_DISTRIBUTIONS:
        print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± box plots Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½...")
        available_features = [f for f in Config.TOP_FEATURES_FOR_PLOTS if f in df.columns]
        
        if available_features:
            n_features = len(available_features)
            n_cols = min(3, n_features)
            n_rows = (n_features + n_cols - 1) // n_cols
            
            fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
            if n_features == 1:
                axes = [axes]
            else:
                axes = axes.ravel() if n_features > 1 else [axes]
            
            for i, feature in enumerate(available_features):
                if i < len(axes):
                    sns.boxplot(data=df, x=' Label', y=feature, ax=axes[i])
                    axes[i].set_title(f'Distribution of {feature}', fontsize=12)
            
            # Î‘Ï€ÏŒÎºÏÏ…ÏˆÎ· ÎºÎµÎ½ÏÎ½ subplots
            for i in range(n_features, len(axes)):
                axes[i].set_visible(False)
            
            plt.tight_layout()
            save_figure(fig, 'top_features_distribution')

# ============================================================================
# 3. Î§Î©Î¡Î™Î£ÎœÎŸÎ£ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î ÎšÎ‘Î™ ÎšÎ‘ÎÎŸÎÎ™ÎšÎŸÎ ÎŸÎ™Î—Î£Î—
# ============================================================================

def prepare_train_test_data(X, y):
    """
    Î§Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Ï„Î± ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯
    
    Returns:
        scaler, X_train, X_test, y_train, y_test
    """
    print_section("Î§Î©Î¡Î™Î£ÎœÎŸÎ£ ÎšÎ‘Î™ ÎšÎ‘ÎÎŸÎÎ™ÎšÎŸÎ ÎŸÎ™Î—Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    
    # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    print("ğŸ”„ ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (StandardScaler)...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ train/test
    print(f"ğŸ”„ Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ train/test sets (test_size={Config.TEST_SIZE})...")
    
    split_params = {
        'test_size': Config.TEST_SIZE,
        'random_state': Config.RANDOM_STATE
    }
    
    if Config.STRATIFY_SPLIT:
        split_params['stratify'] = y
    
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, **split_params)
    
    if Config.PRINT_DETAILED_REPORT:
        print(f"âœ“ Train set: {X_train.shape[0]:,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚ ({X_train.shape[0]/len(X_scaled)*100:.1f}%)")
        print(f"âœ“ Test set: {X_test.shape[0]:,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚ ({X_test.shape[0]/len(X_scaled)*100:.1f}%)")
    
    return scaler, X_train, X_test, y_train, y_test

# ============================================================================
# 4. Î•Î¦Î‘Î¡ÎœÎŸÎ“Î— SMOTE
# ============================================================================

def apply_smote(X_train, y_train):
    """
    Î•Ï†Î±ÏÎ¼ÏŒÎ¶ÎµÎ¹ SMOTE Î³Î¹Î± Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Î±Î½ ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿)
    
    Returns:
        X_train_balanced, y_train_balanced
    """
    if not Config.USE_SMOTE:
        print_section("SMOTE - Î‘Î Î•ÎÎ•Î¡Î“ÎŸÎ ÎŸÎ™Î—ÎœÎ•ÎÎŸ")
        print("âš ï¸ Î¤Î¿ SMOTE ÎµÎ¯Î½Î±Î¹ Î±Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Îµ Î±ÏÏ‡Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±...")
        return X_train, y_train
    
    print_section("Î•Î¦Î‘Î¡ÎœÎŸÎ“Î— SMOTE Î“Î™Î‘ Î™Î£ÎŸÎ¡Î¡ÎŸÎ Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    
    # Import SMOTE
    try:
        from imblearn.over_sampling import SMOTE
    except ImportError:
        print("âš ï¸ Î¤Î¿ imbalanced-learn Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎµÎ³ÎºÎ±Ï„ÎµÏƒÏ„Î·Î¼Î­Î½Î¿!")
        print("   Î•Î³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÏ„Îµ Ï„Î¿ Î¼Îµ: pip install imbalanced-learn")
        print("   Î£Ï…Î½Î­Ï‡ÎµÎ¹Î± Ï‡Ï‰ÏÎ¯Ï‚ SMOTE...")
        return X_train, y_train
    
    # Î‘ÏÏ‡Î¹ÎºÎ® ÎºÎ±Ï„Î±Î½Î¿Î¼Î®
    if Config.PRINT_DETAILED_REPORT:
        print("ğŸ“Š Î‘ÏÏ‡Î¹ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® (Training Set):")
        print(f"   Normal (0): {sum(y_train == 0):,} ({sum(y_train == 0)/len(y_train)*100:.2f}%)")
        print(f"   Attack (1): {sum(y_train == 1):,} ({sum(y_train == 1)/len(y_train)*100:.2f}%)")
        print(f"   Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬: {len(y_train):,}")
    
    # Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE
    print(f"\nâš™ï¸ Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE (sampling_strategy={Config.SMOTE_SAMPLING_STRATEGY})...")
    smote = SMOTE(
        sampling_strategy=Config.SMOTE_SAMPLING_STRATEGY,
        random_state=Config.RANDOM_STATE,
        k_neighbors=Config.SMOTE_K_NEIGHBORS
    )
    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
    
    # ÎÎ­Î± ÎºÎ±Ï„Î±Î½Î¿Î¼Î®
    if Config.PRINT_DETAILED_REPORT:
        print("\nâœ… ÎÎ­Î± ÎšÎ±Ï„Î±Î½Î¿Î¼Î® (Î¼ÎµÏ„Î¬ Ï„Î¿ SMOTE):")
        print(f"   Normal (0): {sum(y_train_balanced == 0):,} ({sum(y_train_balanced == 0)/len(y_train_balanced)*100:.2f}%)")
        print(f"   Attack (1): {sum(y_train_balanced == 1):,} ({sum(y_train_balanced == 1)/len(y_train_balanced)*100:.2f}%)")
        print(f"   Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬: {len(y_train_balanced):,}")
        
        # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
        class_0_increase = sum(y_train_balanced == 0) - sum(y_train == 0)
        class_1_increase = sum(y_train_balanced == 1) - sum(y_train == 1)
        
        if class_0_increase > 0:
            print(f"\nğŸ“ˆ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ SMOTE:")
            print(f"   Î£Ï…Î½Î¸ÎµÏ„Î¹ÎºÎ¬ Normal samples: {class_0_increase:,}")
        if class_1_increase > 0:
            print(f"   Î£Ï…Î½Î¸ÎµÏ„Î¹ÎºÎ¬ Attack samples: {class_1_increase:,}")
    
    # ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    if Config.ENABLE_VISUALIZATIONS and Config.PLOT_SMOTE_COMPARISON:
        print("\nğŸ“Š ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±Ï‚...")
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # Î ÏÎ¹Î½ SMOTE
        sizes_before = [sum(y_train == 0), sum(y_train == 1)]
        labels_pie = ['Normal', 'Attack']
        colors = ['#66b3ff', '#ff9999']
        
        axes[0].pie(sizes_before, labels=labels_pie, autopct='%1.1f%%',
                    colors=colors, startangle=90, textprops={'fontsize': 12})
        axes[0].set_title('Î ÏÎ¹Î½ Ï„Î¿ SMOTE\n(Î‘Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿)', 
                         fontsize=14, fontweight='bold')
        
        # ÎœÎµÏ„Î¬ SMOTE
        sizes_after = [sum(y_train_balanced == 0), sum(y_train_balanced == 1)]
        axes[1].pie(sizes_after, labels=labels_pie, autopct='%1.1f%%',
                    colors=colors, startangle=90, textprops={'fontsize': 12})
        axes[1].set_title(f'ÎœÎµÏ„Î¬ Ï„Î¿ SMOTE\n(Î™ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿)', 
                         fontsize=14, fontweight='bold')
        
        save_figure(fig, 'smote_balance_comparison')
    
    return X_train_balanced, y_train_balanced

# ============================================================================
# 5. Î•ÎšÎ Î‘Î™Î”Î•Î¥Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥
# ============================================================================

def train_model(X_train, y_train, scaler, feature_names):
    """
    Î•ÎºÏ€Î±Î¹Î´ÎµÏÎµÎ¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Logistic Regression
    
    Returns:
        model: Î¤Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿
    """
    print_section("Î•ÎšÎ Î‘Î™Î”Î•Î¥Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥ LOGISTIC REGRESSION")
    
    smote_status = "Î¼Îµ SMOTE-balanced Î´ÎµÎ´Î¿Î¼Î­Î½Î±" if Config.USE_SMOTE else "Ï‡Ï‰ÏÎ¯Ï‚ SMOTE"
    print(f"ğŸ”§ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… {smote_status}...")
    print(f"   - Training samples: {X_train.shape[0]:,}")
    print(f"   - Features: {X_train.shape[1]}")
    print(f"   - Max iterations: {Config.MODEL_MAX_ITER}")
    
    model = LogisticRegression(
        random_state=Config.RANDOM_STATE,
        max_iter=Config.MODEL_MAX_ITER,
        verbose=Config.MODEL_VERBOSE
    )
    
    model.fit(X_train, y_train)
    print("âœ“ Î— ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!")
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    if Config.SAVE_MODEL:
        print(f"\nğŸ’¾ Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ '{Config.MODEL_DIR}/'...")
        ensure_dir(Config.MODEL_DIR)
        
        joblib.dump(model, f'{Config.MODEL_DIR}/logistic_regression_model.joblib')
        joblib.dump(scaler, f'{Config.MODEL_DIR}/scaler.joblib')
        pd.Series(feature_names).to_csv(f'{Config.MODEL_DIR}/feature_names.csv', index=False)
        
        print(f"âœ“ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î±:")
        print(f"  - logistic_regression_model.joblib")
        print(f"  - scaler.joblib")
        print(f"  - feature_names.csv")
    
    return model

# ============================================================================
# 6. Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥
# ============================================================================

def evaluate_model(model, X_test, y_test):
    """Î‘Î¾Î¹Î¿Î»Î¿Î³ÎµÎ¯ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿"""
    print_section("Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥")
    
    # Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚
    print("ğŸ” Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½...")
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # Classification Report
    if Config.PRINT_CLASSIFICATION_REPORT:
        print("\nğŸ“Š Classification Report:")
        print("-" * 70)
        print(classification_report(y_test, y_pred,
                                  target_names=['Normal Traffic', 'Attack Traffic']))
    
    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½
    accuracy = accuracy_score(y_test, y_pred)
    precision_normal = precision_score(y_test, y_pred, pos_label=0, zero_division=0)
    recall_normal = recall_score(y_test, y_pred, pos_label=0, zero_division=0)
    f1_normal = f1_score(y_test, y_pred, pos_label=0, zero_division=0)
    precision_attack = precision_score(y_test, y_pred, pos_label=1, zero_division=0)
    recall_attack = recall_score(y_test, y_pred, pos_label=1, zero_division=0)
    f1_attack = f1_score(y_test, y_pred, pos_label=1, zero_division=0)
    
    # Î£ÏÎ½Î¿ÏˆÎ· Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½
    if Config.PRINT_DETAILED_REPORT:
        print("\nğŸ“Š Î£ÏÎ½Î¿ÏˆÎ· ÎœÎµÏ„ÏÎ¹ÎºÏÎ½:")
        print(f"   Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"\n   Normal Traffic:")
        print(f"     - Precision: {precision_normal:.4f}")
        print(f"     - Recall: {recall_normal:.4f}")
        print(f"     - F1-Score: {f1_normal:.4f}")
        print(f"\n   Attack Traffic:")
        print(f"     - Precision: {precision_attack:.4f}")
        print(f"     - Recall: {recall_attack:.4f}")
        print(f"     - F1-Score: {f1_attack:.4f}")
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½
    if Config.SAVE_METRICS_CSV:
        ensure_dir(Config.RESULTS_DIR)
        metrics_df = pd.DataFrame({
            'Metric': ['Accuracy', 'Normal Precision', 'Normal Recall', 'Normal F1',
                       'Attack Precision', 'Attack Recall', 'Attack F1'],
            'Score': [accuracy, precision_normal, recall_normal, f1_normal,
                      precision_attack, recall_attack, f1_attack]
        })
        metrics_path = f'{Config.RESULTS_DIR}/model_metrics.csv'
        metrics_df.to_csv(metrics_path, index=False)
        if Config.PRINT_DETAILED_REPORT:
            print(f"\nâœ“ ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½: {metrics_path}")
    
    # Confusion Matrix
    if Config.ENABLE_VISUALIZATIONS and Config.PLOT_CONFUSION_MATRIX:
        print("\nğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Confusion Matrix...")
        fig, ax = plt.subplots(figsize=(10, 8))
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, 
                    xticklabels=['Normal', 'Attack'],
                    yticklabels=['Normal', 'Attack'])
        ax.set_title('Confusion Matrix', fontsize=16, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12)
        ax.set_xlabel('Predicted Label', fontsize=12)
        save_figure(fig, 'confusion_matrix')
    
    # ROC Curve
    if Config.ENABLE_VISUALIZATIONS and Config.PLOT_ROC_CURVE:
        print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ROC Curve...")
        fig, ax = plt.subplots(figsize=(10, 8))
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)
        
        ax.plot(fpr, tpr, color='darkorange', lw=2, 
                label=f'ROC curve (AUC = {roc_auc:.4f})')
        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
        ax.set_xlim([0.0, 1.0])
        ax.set_ylim([0.0, 1.05])
        ax.set_xlabel('False Positive Rate', fontsize=12)
        ax.set_ylabel('True Positive Rate', fontsize=12)
        ax.set_title('ROC Curve', fontsize=16, fontweight='bold')
        ax.legend(loc="lower right")
        ax.grid(alpha=0.3)
        save_figure(fig, 'roc_curve')
    else:
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)
    
    return {
        'accuracy': accuracy,
        'precision_normal': precision_normal,
        'recall_normal': recall_normal,
        'f1_normal': f1_normal,
        'precision_attack': precision_attack,
        'recall_attack': recall_attack,
        'f1_attack': f1_attack,
        'roc_auc': roc_auc
    }

# ============================================================================
# 7. Î‘ÎÎ‘Î›Î¥Î£Î— Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸÎ¤Î—Î¤Î‘Î£ Î§Î‘Î¡Î‘ÎšÎ¤Î—Î¡Î™Î£Î¤Î™ÎšÎ©Î
# ============================================================================

def analyze_feature_importance(model, feature_names):
    """Î‘Î½Î±Î»ÏÎµÎ¹ Ï„Î· ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Ï„Ï‰Î½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½"""
    print_section("Î‘ÎÎ‘Î›Î¥Î£Î— Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸÎ¤Î—Î¤Î‘Î£ Î§Î‘Î¡Î‘ÎšÎ¤Î—Î¡Î™Î£Î¤Î™ÎšÎ©Î")
    
    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': abs(model.coef_[0]),
        'coefficient': model.coef_[0]
    })
    feature_importance = feature_importance.sort_values('importance', ascending=False)
    
    # Top N
    if Config.PRINT_DETAILED_REPORT:
        top_n = Config.PRINT_FEATURE_IMPORTANCE_TOP_N
        print(f"ğŸ“Š Top {top_n} Î£Î·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„ÎµÏÎ± Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬:")
        print("-" * 70)
        for idx, row in feature_importance.head(top_n).iterrows():
            sign = '+' if row['coefficient'] > 0 else '-'
            print(f"{row['feature']:50} {row['importance']:.6f} ({sign})")
    
    # ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    if Config.ENABLE_VISUALIZATIONS and Config.PLOT_FEATURE_IMPORTANCE:
        print("\nğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚...")
        fig, ax = plt.subplots(figsize=(12, 10))
        top_features = feature_importance.head(20)
        
        colors = ['#ff9999' if c < 0 else '#99ff99' for c in top_features['coefficient']]
        sns.barplot(data=top_features, x='importance', y='feature', palette=colors, ax=ax)
        
        ax.set_title('Top 20 Most Important Features', fontsize=16, fontweight='bold')
        ax.set_xlabel('Absolute Coefficient Value', fontsize=12)
        ax.set_ylabel('Feature', fontsize=12)
        ax.grid(axis='x', alpha=0.3)
        
        save_figure(fig, 'feature_importance')
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·
    if Config.SAVE_FEATURE_IMPORTANCE_CSV:
        ensure_dir(Config.RESULTS_DIR)
        importance_path = f'{Config.RESULTS_DIR}/feature_importance.csv'
        feature_importance.to_csv(importance_path, index=False)
        if Config.PRINT_DETAILED_REPORT:
            print(f"âœ“ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ: {importance_path}")
    
    return feature_importance

# ============================================================================
# 8. Î¤Î•Î›Î™ÎšÎ— Î£Î¥ÎÎŸÎ¨Î—
# ============================================================================

def print_summary(metrics):
    """Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Ï„ÎµÎ»Î¹ÎºÎ®Ï‚ ÏƒÏÎ½Î¿ÏˆÎ·Ï‚"""
    print_section("Î¤Î•Î›Î™ÎšÎ— Î£Î¥ÎÎŸÎ¨Î— Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î")
    
    print("ğŸ“Œ Î’Î±ÏƒÎ¹ÎºÎ¬ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±:\n")
    
    print(f"1. Î£Î¥ÎÎŸÎ›Î™ÎšÎ— Î‘Î ÎŸÎ”ÎŸÎ£Î—:")
    print(f"   âœ“ Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
    print(f"   âœ“ ROC AUC: {metrics['roc_auc']:.4f}")
    
    print(f"\n2. NORMAL TRAFFIC DETECTION:")
    print(f"   âœ“ Precision: {metrics['precision_normal']:.4f}")
    print(f"   âœ“ Recall: {metrics['recall_normal']:.4f}")
    print(f"   âœ“ F1-Score: {metrics['f1_normal']:.4f}")
    
    print(f"\n3. ATTACK TRAFFIC DETECTION:")
    print(f"   âœ“ Precision: {metrics['precision_attack']:.4f}")
    print(f"   âœ“ Recall: {metrics['recall_attack']:.4f}")
    print(f"   âœ“ F1-Score: {metrics['f1_attack']:.4f}")
    
    print("\n4. Î§Î‘Î¡Î‘ÎšÎ¤Î—Î¡Î™Î£Î¤Î™ÎšÎ‘ ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥:")
    if Config.USE_SMOTE:
        print(f"   âœ“ Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ Î¼Îµ SMOTE-balanced Î´ÎµÎ´Î¿Î¼Î­Î½Î± (sampling_strategy={Config.SMOTE_SAMPLING_STRATEGY})")
    else:
        print("   âœ“ Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ Î¼Îµ Î±ÏÏ‡Î¹ÎºÎ¬ (Î±Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î±) Î´ÎµÎ´Î¿Î¼Î­Î½Î±")
    print("   âœ“ Logistic Regression")
    print(f"   âœ“ Test set: {Config.TEST_SIZE*100:.0f}% Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
    
    print("\n5. Î‘Î ÎŸÎ˜Î—ÎšÎ•Î¥ÎœÎ•ÎÎ‘ Î‘Î¡Î§Î•Î™Î‘:")
    if Config.SAVE_MODEL:
        print(f"   âœ“ ÎœÎ¿Î½Ï„Î­Î»Î¿: {Config.MODEL_DIR}/")
    if Config.ENABLE_VISUALIZATIONS:
        print(f"   âœ“ Î“ÏÎ±Ï†Î®Î¼Î±Ï„Î±: {Config.RESULTS_DIR}/")
    if Config.SAVE_METRICS_CSV or Config.SAVE_FEATURE_IMPORTANCE_CSV:
        print(f"   âœ“ CSV Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±: {Config.RESULTS_DIR}/")

# ============================================================================
# ÎšÎ¥Î¡Î™Î‘ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î—
# ============================================================================

def main():
    """ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï€Î¿Ï… ÎµÎºÏ„ÎµÎ»ÎµÎ¯ ÏŒÎ»Î· Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·"""
    print_header("DDOS DETECTION - Î”Î™Î‘ÎœÎŸÎ¡Î¦Î©Î£Î™ÎœÎŸ Î£Î¥Î£Î¤Î—ÎœÎ‘", "=")
    print("Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹:")
    print(f"  - CSV File: {Config.CSV_FILE}")
    print(f"  - Test Size: {Config.TEST_SIZE*100:.0f}%")
    print(f"  - SMOTE: {'Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿' if Config.USE_SMOTE else 'Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿'}")
    print(f"  - Visualizations: {'Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚' if Config.ENABLE_VISUALIZATIONS else 'Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚'}")
    print(f"  - Save Model: {'ÎÎ±Î¹' if Config.SAVE_MODEL else 'ÎŒÏ‡Î¹'}")
    print()
    
    try:
        # 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
        X, y, feature_names, df = load_and_preprocess_data()
        
        # 2. ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
        visualize_data(X, y, df)
        
        # 3. Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
        scaler, X_train, X_test, y_train, y_test = prepare_train_test_data(X, y)
        
        # 4. SMOTE (Î±Î½ ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿)
        X_train_balanced, y_train_balanced = apply_smote(X_train, y_train)
        
        # 5. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
        model = train_model(X_train_balanced, y_train_balanced, scaler, feature_names)
        
        # 6. Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·
        metrics = evaluate_model(model, X_test, y_test)
        
        # 7. Î‘Î½Î¬Î»Ï…ÏƒÎ· Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
        feature_importance = analyze_feature_importance(model, feature_names)
        
        # 8. Î£ÏÎ½Î¿ÏˆÎ·
        print_summary(metrics)
        
        print_header("ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ• Î•Î Î™Î¤Î¥Î§Î©Î£!", "=")
        print("âœ… Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏÏ„Î·ÎºÎµ ÎºÎ±Î¹ Î±Î¾Î¹Î¿Î»Î¿Î³Î®Î¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚")
        
        if Config.SAVE_MODEL:
            print(f"âœ… Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÏƒÏ„Î¿ '{Config.MODEL_DIR}/'")
        
        if Config.ENABLE_VISUALIZATIONS:
            print(f"âœ… Î¤Î± Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿ '{Config.RESULTS_DIR}/'")
        
        print("\nğŸ’¡ Tip: ÎœÏ€Î¿ÏÎµÎ¯Ï‚ Î½Î± Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ Ï„Î¹Ï‚ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ ÎºÎ»Î¬ÏƒÎ· Config")
        print("   ÏƒÏ„Î·Î½ Î±ÏÏ‡Î® Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î³Î¹Î± Î½Î± Ï€ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÏƒÎµÎ¹Ï‚ Ï„Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±!")
        
    except FileNotFoundError as e:
        print(f"\nâŒ Î£Ï†Î¬Î»Î¼Î±: {str(e)}")
        return 1
    except Exception as e:
        print(f"\nâŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

# ============================================================================
# Î•ÎšÎ¤Î•Î›Î•Î£Î—
# ============================================================================

if __name__ == "__main__":
    exit(main())

# DrDoS DNS Attack Detection

## Overview
DrDoS-Detector is a machine learning pipeline for detecting Distributed Reflection Denial of Service (DrDoS) attacks targeting DNS servers. The project supports multiple classification algorithms, automatic model comparison, robust handling of class imbalance with SMOTE applied before splitting, and clean separation of training vs. evaluation data to avoid leakage.

- Multiple models with enable/disable configuration
- Automatic per-model timing (training, evaluation, total)
- Clean test set with only original, non-SMOTE data
- Auto-saved results and best-model artifacts with incremental filenames
- Modular codebase designed for reproducibility and maintenance

## Supported Algorithms
- Logistic Regression (as referenced in the paper)
- Random Forest
- Decision Tree (fast and high-performing)
- Support Vector Machine (SVM)
- K-Nearest Neighbors (KNN)

## Quick Start

### Requirements
```txt
pandas>=1.5.0
numpy>=1.23.0
scikit-learn>=1.2.0
imbalanced-learn>=0.10.0
```

### Install
```bash
pip install pandas numpy scikit-learn imbalanced-learn
```

### Dataset
- File: `DrDoS_DNS.csv`
- Download: available in GitHub Releases
- Place the CSV in the project root folder

Releases: https://github.com/kulisk/DrDoS-Detector/releases

### Run
```bash
python train.py
```

Default configuration trains and compares multiple models. Results and artifacts are saved automatically.

## Configuration
Edit `train.py` to select and configure models.

- Enable or disable models:
```python
ENABLE_MODELS = {
  'Logistic Regression': True,
  'Random Forest': True,
  'SVM': False,
  'Decision Tree': True,
  'KNN': False
}
```

- Global settings:
```python
TEST_SIZE = 0.20           # Evaluation ratio (20%)
SMOTE_TARGET_RATIO = 10    # BENIGN upsampling multiplier
RANDOM_STATE = 42          # Reproducibility
```

- Per-model parameters (excerpt):
```python
MODEL_PARAMS = {
  'Logistic Regression': {
    'max_iter': 1000,
    'random_state': RANDOM_STATE
  },
  'Random Forest': {
    'n_estimators': 100,
    'max_depth': 30,
    'min_samples_split': 5,
    'min_samples_leaf': 2,
    'random_state': RANDOM_STATE
  },
  'SVM': {
    'kernel': 'rbf',
    'C': 1.0,
    'random_state': RANDOM_STATE
  },
  'Decision Tree': {
    'max_depth': 30,
    'min_samples_split': 5,
    'min_samples_leaf': 2,
    'random_state': RANDOM_STATE
  },
  'KNN': {
    'n_neighbors': 5,
    'weights': 'uniform'
  }
}
```

## Pipeline

### Data Flow (corrected design)
```
DrDoS_DNS.csv (5M+ samples, ~0.07% BENIGN, ~99.93% DrDoS)
  â†“
[1] data_preprocessing.py
  â”œâ”€ Clean null/inf
  â”œâ”€ Encode categorical â†’ numeric
  â””â”€ Split X, y
  â†“
[2] Class separation
  â”œâ”€ BENIGN (original)
  â””â”€ DrDoS (original)
  â†“
[3] data_balancing.py (SMOTE BEFORE SPLIT)
  â”œâ”€ Input: BENIGN original
  â”œâ”€ SMOTE to target ratio (e.g., 10Ã—)
  â””â”€ Output: BENIGN SMOTE
  â†“
[4] data_splitting.py (AFTER SMOTE)
  â”œâ”€ Test: ALL original BENIGN + equal DrDoS
  â””â”€ Train: BENIGN SMOTE + remaining DrDoS
  â†“
[5] model_training.py
  â”œâ”€ StandardScaler fit on train â†’ transform train/test
  â””â”€ Train selected models (with timing)
  â†“
[6] model_evaluation.py
  â”œâ”€ Evaluate on PURE original test data
  â”œâ”€ Metrics: Accuracy, Precision, Recall, F1
  â””â”€ Feature importance / coefficients (Top 20)
  â†“
[7] model_comparison.py (if multiple models enabled)
  â”œâ”€ Compare metrics & timing
  â”œâ”€ Save comparison report
  â””â”€ Select best model
  â†“
[8] model_persistence.py
  â””â”€ Save best model and supporting artifacts
```

## Modules

- `data_preprocessing.py`
  - `load_dataset(csv_path)`
  - `clean_data(df)` â†’ cleans + encodes + returns X, y
  - `encode_labels(y)`

- `data_balancing.py`
  - `apply_smote_to_benign(X_benign, y_benign, target_samples, random_state)`

- `data_splitting.py`
  - `split_data_after_smote(...)` â†’ Test: ALL original BENIGN + equal DrDoS; Train: BENIGN SMOTE + remaining DrDoS

- `model_training.py`
  - `scale_features(X_train, X_test)`
  - `train_logistic_regression(...)`
  - `train_random_forest(...)`
  - `train_svm(...)`
  - `train_decision_tree(...)`
  - `train_knn(...)`

- `model_evaluation.py`
  - `evaluate_model(clf, X_test, y_test, le_label, feature_names)`
  - Handles tree-based `feature_importances_` and linear `coef_` (abs)
  - Saves individual results with auto-increment: `training_results_#.txt`

- `model_comparison.py`
  - `compare_models(results_dict, label_encoder)` â†’ table of metrics + timing
  - `save_comparison_to_file(...)` â†’ `comparison_results_#.txt`
  - Best model selection stored as `best_model_[algorithm].pkl`

- `model_persistence.py`
  - `save_model(model, scaler, label_encoder, feature_names, filepath)`
  - `load_model(filepath)`

## Results Snapshot

Example comparative performance (with 6,708 original test samples):

| Model               | Accuracy | Precision | Recall | F1-Score | Train Time | Total Time |
|---------------------|----------|-----------|--------|----------|------------|------------|
| Decision Tree       | 0.9999   | 0.9999    | 0.9999 | 0.9999   | 0.36 s     | 0.39 s     |
| Logistic Regression | 0.9996   | 0.9996    | 0.9996 | 0.9996   | 5.20 s     | 5.26 s     |
| Random Forest       | 0.9994   | 0.9994    | 0.9994 | 0.9994   | 0.62 s     | 0.79 s     |

Notes:
- Test set uses only original samples (no SMOTE)
- Auto-comparison report: `comparison_results_#.txt`
- Best model artifact: `best_model_[algorithm].pkl`

## Using Saved Models
```python
from model_persistence import load_model
import pandas as pd

model_data = load_model('best_model_decision_tree.pkl')
clf = model_data['model']
scaler = model_data['scaler']
label_encoder = model_data['label_encoder']
feature_names = model_data['feature_names']

# X_new must match training feature schema
X_new = pd.DataFrame(..., columns=feature_names)
X_new_scaled = scaler.transform(X_new)
pred = clf.predict(X_new_scaled)
labels = label_encoder.inverse_transform(pred)
print(labels)
```

## Project Structure
```
DrDoS-Detector/
â”œâ”€â”€ train.py
â”œâ”€â”€ data_preprocessing.py
â”œâ”€â”€ data_balancing.py
â”œâ”€â”€ data_splitting.py
â”œâ”€â”€ model_training.py
â”œâ”€â”€ model_evaluation.py
â”œâ”€â”€ model_comparison.py
â”œâ”€â”€ model_persistence.py
â”œâ”€â”€ DrDoS_DNS.csv                 # download from Releases
â”œâ”€â”€ training_results_*.txt
â”œâ”€â”€ comparison_results_*.txt
â”œâ”€â”€ best_model_*.pkl
â””â”€â”€ README.md
```

## Troubleshooting
- Memory constraints: reduce `SMOTE_TARGET_RATIO` (e.g., 5) or `TEST_SIZE` (e.g., 0.10)
- Slow training: disable SVM and KNN for large datasets; keep Decision Tree and Random Forest
- Dataset not found: ensure `DrDoS_DNS.csv` is in the project root

## Reference
Paper: â€œPredicting of DDoS Attack on DNS Server using Machine Learningâ€
- Uses Logistic Regression
- This implementation also compares additional models and achieves >99.9% accuracy with clean evaluation design

## License
Open-source for educational and research use.

## Contact
- Issues: https://github.com/kulisk/DrDoS-Detector/issues
- Releases: https://github.com/kulisk/DrDoS-Detector/releases

# DrDoS DNS Attack Detection - Project Documentation

## Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·
Î ÏÎ¿Î·Î³Î¼Î­Î½Î¿ ÏƒÏÏƒÏ„Î·Î¼Î± Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ·Ï‚ ÎµÏ€Î¹Î¸Î­ÏƒÎµÏ‰Î½ DrDoS (Distributed Reflection Denial of Service) Î¼Îµ Ï‡ÏÎ®ÏƒÎ· Machine Learning. Î¤Î¿ ÏƒÏÏƒÏ„Î·Î¼Î± Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ **Ï€Î¿Î»Î»Î±Ï€Î»Î¿ÏÏ‚ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…Ï‚** Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚ Î¼Îµ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± **Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î·Ï‚ ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·Ï‚** ÎºÎ±Î¹ ÎµÏ†Î±ÏÎ¼ÏŒÎ¶ÎµÎ¹ **SMOTE Î Î¡Î™Î Ï„Î¿ splitting** Î³Î¹Î± ÏƒÏ‰ÏƒÏ„Î® Î±Î½Ï„Î¹Î¼ÎµÏ„ÏÏ€Î¹ÏƒÎ· Î±Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½, ÎµÎ¾Î±ÏƒÏ†Î±Î»Î¯Î¶Î¿Î½Ï„Î±Ï‚ ÏŒÏ„Î¹ Ï„Î¿ test set Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ **ÎœÎŸÎÎŸ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±** (ÏŒÏ‡Î¹ SMOTE).

### ğŸ¯ Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î¿Î¹ Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹
- **Logistic Regression** (ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹ Î±Ï€ÏŒ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿)
- **Random Forest**
- **Decision Tree** ğŸ† (ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·)
- **Support Vector Machine (SVM)**
- **K-Nearest Neighbors (KNN)**

---

## Î”Î¿Î¼Î® Î‘ÏÏ‡ÎµÎ¯Ï‰Î½ ÎºÎ±Î¹ Î£ÎµÎ¹ÏÎ¬ Î•ÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚

### ğŸš€ ÎšÏÏÎ¹Î¿ Script Î•ÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚

#### **`train.py`**
Î¤Î¿ ÎºÏÏÎ¹Î¿ script Ï€Î¿Ï… Î¿ÏÏ‡Î·ÏƒÏ„ÏÏÎ½ÎµÎ¹ Î¿Î»ÏŒÎºÎ»Î·ÏÎ· Ï„Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ Î¼Îµ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½.

**Î•ÎºÏ„ÎµÎ»ÎµÎ¯ Î¼Îµ Ï„Î· ÏƒÎµÎ¹ÏÎ¬:**
1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
2. ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒ ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
3. Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒ ÏƒÎµ BENIGN ÎºÎ±Î¹ DDoS classes
4. **Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE ÏƒÏ„Î± BENIGN (Î Î¡Î™Î Ï„Î¿ splitting)**
5. Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒ ÏƒÎµ train/test sets (test = ÎŸÎ›Î‘ Ï„Î± original BENIGN + Î¯ÏƒÎ± DDoS)
6. ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· features
7. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î¼Îµ Î¼Î­Ï„ÏÎ·ÏƒÎ· Ï‡ÏÏŒÎ½Î¿Ï…
8. Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
9. Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ (Î±Î½ >1 enabled)
10. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î¿Ï… ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…

**Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î‘Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½:**
```python
ENABLE_MODELS = {
    'Logistic Regression': True,   # Î‘Ï€ÏŒ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿
    'Random Forest': True,          # Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ® Î±Ï€ÏŒÎ´Î¿ÏƒÎ·
    'SVM': False,                   # Î‘ÏÎ³ÏŒÏ‚ Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± datasets
    'Decision Tree': True,          # Î¤Î±Ï‡ÏÏ„ÎµÏÎ¿Ï‚ & Î‘ÎºÏÎ¹Î²Î­ÏƒÏ„ÎµÏÎ¿Ï‚
    'KNN': False                    # Î Î¿Î»Ï Î±ÏÎ³ÏŒÏ‚
}
```

**Î•ÎºÏ„Î­Î»ÎµÏƒÎ·:**
```bash
python train.py
```

---

## Modules (Î¼Îµ ÏƒÎµÎ¹ÏÎ¬ ÎºÎ»Î®ÏƒÎ·Ï‚)

### 1ï¸âƒ£ **`data_preprocessing.py`**
Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… dataset.

**Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚:**
- `load_dataset(csv_path)` - Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ CSV Î±ÏÏ‡ÎµÎ¯Î¿
- `clean_data(df)` - ÎšÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±:
  - Î‘Ï†Î±Î¹ÏÎµÎ¯ Î¬Ï‡ÏÎ·ÏƒÏ„ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ (Unnamed: 0, Flow ID, Timestamp)
  - Î§ÎµÎ¹ÏÎ¯Î¶ÎµÏ„Î±Î¹ null ÎºÎ±Î¹ infinity Ï„Î¹Î¼Î­Ï‚
  - ÎšÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯ categorical features
  - Î”Î¹Î±Ï‡Ï‰ÏÎ¯Î¶ÎµÎ¹ features Î±Ï€ÏŒ labels
- `encode_labels(y)` - ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ string labels ÏƒÎµ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚

**ÎˆÎ¾Î¿Î´Î¿Ï‚:**
- Features DataFrame (X)
- Labels Series (y)
- Label Encoder

---

### 2ï¸âƒ£ **`data_balancing.py`**
Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE ÏƒÏ„Î± BENIGN Î´ÎµÎ´Î¿Î¼Î­Î½Î± **Î Î¡Î™Î Ï„Î¿ splitting**.

**Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚:**
- `apply_smote_to_benign(X_benign, y_benign, target_samples, random_state)` - Î•Ï†Î±ÏÎ¼ÏŒÎ¶ÎµÎ¹ SMOTE:

**Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ®:**
- **SMOTE ÎµÏ†Î±ÏÎ¼ÏŒÎ¶ÎµÏ„Î±Î¹ Î Î¡Î©Î¤Î‘** ÏƒÏ„Î·Î½ minority class (BENIGN)
- Î‘Ï…Î¾Î¬Î½ÎµÎ¹ Ï„Î± BENIGN samples Î±Ï€ÏŒ ~3.4K â†’ ~33.5K (10x)
- Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ ÏƒÏ…Î½Î¸ÎµÏ„Î¹ÎºÎ¬ Î´ÎµÎ¯Î³Î¼Î±Ï„Î± Î³Î¹Î± ÎµÎ¾Î¹ÏƒÎ¿ÏÏÏŒÏ€Î·ÏƒÎ·
- Î¡Ï…Î¸Î¼Î¹Î¶ÏŒÎ¼ÎµÎ½Î¿ target (SMOTE_TARGET_RATIO ÏƒÏ„Î¿ train.py)

**ÎˆÎ¾Î¿Î´Î¿Ï‚:**
- SMOTE-augmented BENIGN features ÎºÎ±Î¹ labels
- Î¤Î± original BENIGN Î´Î¹Î±Ï„Î·ÏÎ¿ÏÎ½Ï„Î±Î¹ Î¾ÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„Î¬ Î³Î¹Î± Ï„Î¿ test set

---

### 3ï¸âƒ£ **`data_splitting.py`**
Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÎµ training ÎºÎ±Î¹ test sets **ÎœÎ•Î¤Î‘ Ï„Î¿ SMOTE**.

**Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚:**
- `split_data_after_smote(X_benign_original, y_benign_original, X_benign_smote, y_benign_smote, X_attack, y_attack, le_label, test_size, random_state)` - Î§Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±:

**Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® (Î”Î™ÎŸÎ¡Î˜Î©ÎœÎ•ÎÎ—):**
1. **Test Set:**
   - **ÎŸÎ›Î‘** Ï„Î± original BENIGN samples (3,354)
   - ÎŠÏƒÎ¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ DDoS samples (3,354) - Ï„Ï…Ï‡Î±Î¯Î± ÎµÏ€Î¹Î»Î¿Î³Î®
   - Î£ÏÎ½Î¿Î»Î¿: 6,708 samples (50-50 balanced)
   - **ÎšÎ‘ÎÎ•ÎÎ‘ SMOTE Î´ÎµÎ´Î¿Î¼Î­Î½Î¿**

2. **Train Set:**
   - SMOTE BENIGN samples (subsample Î³Î¹Î± Î½Î± Ï„Î±Î¹ÏÎ¹Î¬Î¾ÎµÎ¹ Ï„Î¿ test_size ratio)
   - ÎŠÏƒÎ¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ DDoS samples - Ï„Ï…Ï‡Î±Î¯Î± ÎµÏ€Î¹Î»Î¿Î³Î® Î±Ï€ÏŒ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î±
   - Î•Î¾Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿ 50-50

3. **Test Size Ratio:**
   - Î¡Ï…Î¸Î¼Î¹Î¶ÏŒÎ¼ÎµÎ½Î¿ (default 20%)
   - Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÏ„Î±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±: test / (train + test)

**ÎˆÎ¾Î¿Î´Î¿Ï‚:**
- X_train, y_train (balanced, Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ SMOTE)
- X_test, y_test (balanced, ÎœÎŸÎÎŸ original data)

---

### 4ï¸âƒ£ **`model_training.py`**
ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· features ÎºÎ±Î¹ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î¼Îµ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½.

**Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚:**
- `scale_features(X_train, X_test)` - StandardScaler Î³Î¹Î± ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
  - Fit ÏƒÏ„Î¿ training set
  - Transform ÏƒÎµ train ÎºÎ±Î¹ test

**Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚:**
- `train_logistic_regression(...)` - Logistic Regression (Î±Ï€ÏŒ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿)
  - max_iter: 1000
  - Î Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± (n_jobs=-1)
  
- `train_random_forest(...)` - Random Forest
  - 100 trees, max_depth=30
  - Î Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± (n_jobs=-1)
  
- `train_svm(...)` - Support Vector Machine
  - RBF kernel, C=1.0
  
- `train_decision_tree(...)` - Decision Tree
  - max_depth=30
  
- `train_knn(...)` - K-Nearest Neighbors
  - k=5, uniform weights

**Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬:**
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ **ÎŸÎ›Î•Î£** Ï„Î¹Ï‚ 84 ÏƒÏ„Î®Î»ÎµÏ‚
- Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· coefficient-based ÎºÎ±Î¹ tree-based Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
- Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î¼Î­Ï„ÏÎ·ÏƒÎ· Ï‡ÏÏŒÎ½Î¿Ï… ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚

**ÎˆÎ¾Î¿Î´Î¿Ï‚:**
- Scaler (fitted)
- Trained Classifier (Î¿Ï€Î¿Î¹Î¿ÏƒÎ´Î®Ï€Î¿Ï„Îµ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚)

---

### 5ï¸âƒ£ **`model_evaluation.py`**
Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Ï„Ï‰Î½ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Î¼Îµ Ï€Î»Î®ÏÎ· Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚.

**Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚:**
- `evaluate_model(clf, X_test, y_test, le_label, feature_names)` - Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹:

**ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚:**
- Confusion Matrix
- Classification Report (per-class metrics)
- Accuracy, Precision, Recall, F1-Score
- Feature Importance / Coefficients (Top 20)
  - Tree-based models: feature_importances_
  - Linear models: abs(coef_)

**Î§ÏÏŒÎ½Î¿Î¹ Î•ÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚:**
- Training Time (Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±)
- Evaluation Time (Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±)
- Total Time (Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±)

**Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½:**
- `save_results_to_file()` - Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÎµ `training_results_X.txt`
- Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î±ÏÎ¯Î¸Î¼Î·ÏƒÎ· Î±ÏÏ‡ÎµÎ¯Ï‰Î½ (Î´ÎµÎ½ Î³Î¯Î½ÎµÏ„Î±Î¹ overwrite)

**Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·:** Î¤Î¿ test set Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ **ÎœÎŸÎÎŸ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±**, ÏŒÏ‡Î¹ SMOTE!

**ÎˆÎ¾Î¿Î´Î¿Ï‚:**
- Dictionary Î¼Îµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚ + Ï‡ÏÏŒÎ½Î¿Ï…Ï‚
- Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ÏƒÏ„Î·Î½ ÎºÎ¿Î½ÏƒÏŒÎ»Î±
- Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÎµ txt Î±ÏÏ‡ÎµÎ¯Î¿

---

### 6ï¸âƒ£ **`model_comparison.py`**
Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ ÎºÎ±Î¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± comparative analysis.

**Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚:**
- `compare_models(results_dict, label_encoder)` - Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï€Î¯Î½Î±ÎºÎ± ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·Ï‚:
  - Accuracy, Precision, Recall, F1-Score
  - Training Time, Total Time
  - Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· (ÎºÎ±Ï„Î¬ Accuracy)
  - Î ÏÎ¿ÏƒÎ´Î¹Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…

- `save_comparison_to_file(...)` - Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î»ÎµÏ€Ï„Î¿Î¼ÎµÏÎ¿ÏÏ‚ ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·Ï‚:
  - Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÏŒÏ‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚
  - Detailed results Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿
  - Confusion matrices
  - Top 10 features per model
  - Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î±ÏÎ¯Î¸Î¼Î·ÏƒÎ·: `comparison_results_X.txt`

**Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±:**
- Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± ÏŒÏ„Î±Î½ >1 Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ enabled
- Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹ Ï„Î¿ **ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿** Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±

**ÎˆÎ¾Î¿Î´Î¿Ï‚:**
- Comparison DataFrame
- `comparison_results_X.txt` Î¼Îµ Ï€Î»Î®ÏÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·
- `best_model_[algorithm_name].pkl`

---

### 7ï¸âƒ£ **`model_persistence.py`**
### 7ï¸âƒ£ **`model_persistence.py`**
Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎºÎ±Î¹ Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï….

**Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚:**
- `save_model(model, scaler, label_encoder, feature_names, filepath)` - Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹:
  - Trained model (Î¿Ï€Î¿Î¹Î¿ÏƒÎ´Î®Ï€Î¿Ï„Îµ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚)
  - Scaler
  - Label encoder
  - Feature names
  
- `load_model(filepath)` - Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿

**ÎˆÎ¾Î¿Î´Î¿Ï‚:**
- `drdos_detector_model.pkl` Î® `best_model_[algorithm].pkl`
- Pickle file Î¼Îµ ÏŒÎ»Î± Ï„Î± Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± objects

---

## Î¡Î¿Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Î”Î™ÎŸÎ¡Î˜Î©ÎœÎ•ÎÎ—)

```
DrDoS_DNS.csv (5M+ samples, 99.93% DDoS, 0.07% BENIGN)
    â†“
[1] data_preprocessing.py
    â”œâ”€ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ (null, inf)
    â”œâ”€ Encoding (categorical â†’ numeric)
    â””â”€ Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ X, y
    â†“
[2] Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Classes
    â”œâ”€ BENIGN: 3,354 samples (original)
    â””â”€ DDoS: 4,908,665 samples
    â†“
[3] data_balancing.py - SMOTE Î Î¡Î™Î Î¤ÎŸ SPLITTING
    â”œâ”€ Input: BENIGN (3,354)
    â”œâ”€ SMOTE: 3,354 â†’ 33,540 (10x)
    â””â”€ Output: SMOTE BENIGN (33,540)
    â†“
[4] data_splitting.py - Splitting ÎœÎ•Î¤Î‘ Î¤ÎŸ SMOTE
    â”œâ”€ Test Set (6,708):
    â”‚   â”œâ”€ ALL original BENIGN: 3,354
    â”‚   â””â”€ DDoS (random): 3,354
    â”‚   â””â”€ Ratio: 50-50, ÎšÎ‘ÎÎ•ÎÎ‘ SMOTE!
    â”‚
    â””â”€ Train Set (26,832):
        â”œâ”€ SMOTE BENIGN (subsample): 13,416
        â””â”€ DDoS (random): 13,416
        â””â”€ Ratio: 50-50, balanced
    â†“
    â””â”€ Test ratio: 20% (configurable)
    â†“
[5] model_training.py
    â”œâ”€ StandardScaler (normalization)
    â””â”€ Train Multiple Models Î¼Îµ Ï‡ÏÎ¿Î½Î¿Î¼Î­Ï„ÏÎ·ÏƒÎ·
    â†“
[6] model_evaluation.py
    â”œâ”€ Predictions on PURE original data
    â”œâ”€ Metrics Calculation Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿
    â””â”€ Î§ÏÏŒÎ½Î¿Î¹ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
    â†“
[7] model_comparison.py (Î±Î½ >1 model enabled)
    â”œâ”€ Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ·
    â”œâ”€ Î•Ï€Î¹Î»Î¿Î³Î® ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    â””â”€ Save comparison_results_X.txt
    â†“
[8] model_persistence.py
    â””â”€ Save â†’ best_model_[algorithm].pkl
```

---

## Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±

### ğŸ“Š Performance Metrics (Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î‘Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½)

| ÎœÎ¿Î½Ï„Î­Î»Î¿ | Accuracy | Precision | Recall | F1-Score | Training Time | Total Time |
|---------|----------|-----------|--------|----------|---------------|------------|
| **Decision Tree** ğŸ† | **99.99%** | **99.99%** | **99.99%** | **99.99%** | **0.36s** âš¡ | **0.39s** âš¡ |
| **Logistic Regression** | 99.96% | 99.96% | 99.96% | 99.96% | 5.20s | 5.26s |
| **Random Forest** | 99.94% | 99.94% | 99.94% | 99.94% | 0.62s | 0.79s |

**Î£Î·Î¼ÎµÎ¹ÏÏƒÎµÎ¹Ï‚:**
- **Decision Tree**: ÎšÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· ÎšÎ‘Î™ Ï„Î±Ï‡ÏÏ„Î·Ï„Î± (Î¼ÏŒÎ½Î¿ 1 Î»Î¬Î¸Î¿Ï‚ ÏƒÏ„Î± 6,708 samples!)
- **Logistic Regression**: Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ Ï€Î¿Ï… ÏƒÏ…ÏƒÏ„Î®Î½ÎµÏ„Î±Î¹ Î±Ï€ÏŒ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿, ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ® Î±ÎºÏÎ¯Î²ÎµÎ¹Î±
- **Random Forest**: Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ® Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚/Ï„Î±Ï‡ÏÏ„Î·Ï„Î±Ï‚
- **Test Set**: 6,708 samples (100% original data, 0% SMOTE)

### ğŸ¯ Top Features (Decision Tree)
1. Source IP (99.93%)
2. Min Packet Length (0.06%)
3. Destination Port (0.01%)
4. min_seg_size_forward (<0.01%)
5. Destination IP (<0.01%)

### ğŸ¯ Top Features (Logistic Regression)
1. Source IP (3.35)
2. Destination IP (2.63)
3. URG Flag Count (2.18)
4. Protocol (1.98)
5. Bwd Packet Length Min (0.80)

### ğŸ¯ Top Features (Random Forest)
1. Source IP (13.3%)
2. Min Packet Length (8.2%)
3. Avg Fwd Segment Size (7.2%)
4. Average Packet Size (7.2%)
5. Fwd Packet Length Min (7.2%)

---

## Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚

### âœ… Î Î¿Î»Î»Î±Ï€Î»Î¿Î¯ Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ ML
- **5 Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿Î¯ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹** Î¼Îµ ÎµÏÎºÎ¿Î»Î· ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·/Î±Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·
- **Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·** ÏŒÏ„Î±Î½ >1 Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ enabled
- **Î•Ï€Î¹Î»Î¿Î³Î® ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…** Î¼Îµ Î²Î¬ÏƒÎ· accuracy
- **Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· coefficient & tree-based models**

### âœ… ÎœÎ­Ï„ÏÎ·ÏƒÎ· Î§ÏÏŒÎ½Ï‰Î½ Î•ÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
- **Training Time** Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿
- **Evaluation Time** Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿
- **Total Time** (end-to-end)
- Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÏƒÎµ Ï€Î¯Î½Î±ÎºÎ± ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·Ï‚

### âœ… Î£Ï‰ÏƒÏ„Î® Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· SMOTE
- **SMOTE ÎµÏ†Î±ÏÎ¼ÏŒÎ¶ÎµÏ„Î±Î¹ Î Î¡Î™Î Ï„Î¿ splitting** (ÏŒÏ‡Î¹ Î¼ÎµÏ„Î¬!)
- Test set Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ **ÎœÎŸÎÎŸ original BENIGN** data
- Train set Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ **SMOTE-augmented** data
- Î‘Ï€Î¿Ï†Ï…Î³Î® data leakage

### âœ… Test Set Strategy
- **ÎŸÎ›Î‘ Ï„Î± original BENIGN** Î³Î¹Î± realistic evaluation
- **Î•Î¾Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿ 50-50** Î¼Îµ Î¯ÏƒÎ± DDoS samples
- **ÎšÎ±Î½Î­Î½Î± ÏƒÏ…Î½Î¸ÎµÏ„Î¹ÎºÏŒ Î´ÎµÎ´Î¿Î¼Î­Î½Î¿** (SMOTE-free)
- **Î¤Ï…Ï‡Î±Î¯Î± ÎµÏ€Î¹Î»Î¿Î³Î® DDoS** Ï‡Ï‰ÏÎ¯Ï‚ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±

### âœ… Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
- **Auto-incrementing filenames** (Î´ÎµÎ½ Î³Î¯Î½ÎµÏ„Î±Î¹ overwrite)
- `training_results_X.txt` - ÎœÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
- `comparison_results_X.txt` - Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ·
- `best_model_[algorithm].pkl` - Î¤Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿

### âœ… Î¡Ï…Î¸Î¼Î¹Î¶ÏŒÎ¼ÎµÎ½ÎµÏ‚ Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹
- `ENABLE_MODELS` - Î•Ï€Î¹Î»Î¿Î³Î® Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ (True/False)
- `TEST_SIZE` - Test set ratio (default 0.20 = 20%)
- `SMOTE_TARGET_RATIO` - SMOTE multiplier (default 10x)
- `MODEL_PARAMS` - Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿

### âœ… Î¤ÎµÏ‡Î½Î¹ÎºÎ¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
- **Î§ÏÎ®ÏƒÎ· ÎŸÎ›Î©Î Ï„Ï‰Î½ ÏƒÏ„Î·Î»ÏÎ½** (84 features)
- **StandardScaler** normalization Î³Î¹Î± ÏŒÎ»Î± Ï„Î± Î¼Î¿Î½Ï„Î­Î»Î±
- **Parallel processing** ÏŒÏ€Î¿Ï… Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÏ„Î±Î¹ (n_jobs=-1)
- **Modular design** Î³Î¹Î± ÎµÏÎºÎ¿Î»Î· ÏƒÏ…Î½Ï„Î®ÏÎ·ÏƒÎ·
- **Reproducible** (random_state=42)

---

## Î§ÏÎ®ÏƒÎ·

### ğŸš€ Î“ÏÎ®Î³Î¿ÏÎ· Î•ÎºÎºÎ¯Î½Î·ÏƒÎ·

#### 1. Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÏ‰Î½
```bash
pip install pandas numpy scikit-learn imbalanced-learn
```

#### 2. Î›Î®ÏˆÎ· Dataset
ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ `DrDoS_DNS.csv` Î±Ï€ÏŒ Ï„Î± [GitHub Releases](https://github.com/kulisk/DrDoS-Detector/releases) ÎºÎ±Î¹ Ï„Î¿Ï€Î¿Î¸ÎµÏ„Î®ÏƒÏ„Îµ Ï„Î¿ ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ Ï„Î¿Ï… project.

#### 3. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Îµ Default Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚
```bash
python train.py
```

**Default Configuration:**
- Enabled: Logistic Regression, Random Forest, Decision Tree
- Disabled: SVM, KNN (Î±ÏÎ³Î¿Î¯ Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± datasets)
- Test Size: 20%
- SMOTE Ratio: 10x

---

### âš™ï¸ Î ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î· Î§ÏÎ®ÏƒÎ·

#### Î•Ï€Î¹Î»Î¿Î³Î® Î‘Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½
Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÏ„ÎµÎ¯Ï„Îµ Ï„Î¿ `train.py` (Î³ÏÎ±Î¼Î¼Î­Ï‚ 25-31):
```python
ENABLE_MODELS = {
    'Logistic Regression': True,   # Î‘Ï€ÏŒ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿ - Î‘ÏÎ³ÏŒÏ‚ Î±Î»Î»Î¬ Î±ÎºÏÎ¹Î²Î®Ï‚
    'Random Forest': True,          # ÎšÎ±Î»Î® Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±
    'SVM': False,                   # Î Î¿Î»Ï Î±ÏÎ³ÏŒÏ‚ (enable Î¼ÏŒÎ½Î¿ Î³Î¹Î± Î¼Î¹ÎºÏÎ¬ datasets)
    'Decision Tree': True,          # Î¤Î±Ï‡ÏÏ„ÎµÏÎ¿Ï‚ & ÎšÎ±Î»ÏÏ„ÎµÏÎ¿Ï‚ ğŸ†
    'KNN': False                    # Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ Î±ÏÎ³ÏŒÏ‚ (Î±Ï€Î¿Ï†ÏÎ³ÎµÏ„Îµ)
}
```

#### Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½
Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÏ„ÎµÎ¯Ï„Îµ Ï„Î¿ `train.py`:
```python
TEST_SIZE = 0.20              # Test set ratio (20%)
SMOTE_TARGET_RATIO = 10       # SMOTE multiplier (10x original BENIGN)
RANDOM_STATE = 42             # Î“Î¹Î± reproducibility
```

#### Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Model Parameters
Î¤ÏÎ¿Ï€Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿ dictionary `MODEL_PARAMS` ÏƒÏ„Î¿ `train.py`:
```python
MODEL_PARAMS = {
    'Logistic Regression': {
        'max_iter': 1000,
        'random_state': RANDOM_STATE
    },
    'Random Forest': {
        'n_estimators': 100,      # Î ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± trees = ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·
        'max_depth': 30,
        'min_samples_split': 5,
        'min_samples_leaf': 2,
        'random_state': RANDOM_STATE
    },
    # ... Î¬Î»Î»Î¿Î¹ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹
}
```

---

### ğŸ“Š ÎˆÎ¾Î¿Î´Î¿Ï‚ Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½

#### Single Model Mode (1 enabled)
- Console output Î¼Îµ Ï€Î»Î®ÏÎ· Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚
- `training_results_X.txt` Î¼Îµ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
- `drdos_detector_model.pkl` Î¼Îµ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿

#### Comparison Mode (>1 enabled)
- Console output Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¼Î¿Î½Ï„Î­Î»Î¿
- Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÏŒÏ‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚ ÏƒÏ„Î·Î½ ÎºÎ¿Î½ÏƒÏŒÎ»Î±
- `comparison_results_X.txt` Î¼Îµ Ï€Î»Î®ÏÎ· ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·
- `best_model_[algorithm].pkl` Î¼Îµ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿

**Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î± Comparison Output:**
```
================================================================================
MODEL COMPARISON
================================================================================
              Model Accuracy Precision Recall F1-Score Training Time (s) Total Time (s)
      Decision Tree   0.9999    0.9999 0.9999   0.9999              0.36           0.39
Logistic Regression   0.9996    0.9996 0.9996   0.9996              5.20           5.26
      Random Forest   0.9994    0.9994 0.9994   0.9994              0.62           0.79
================================================================================
ğŸ† Best Model: Decision Tree
================================================================================
```

---

### ğŸ”® Î§ÏÎ®ÏƒÎ· Î‘Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿Ï… ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… Î³Î¹Î± Predictions
### ğŸ”® Î§ÏÎ®ÏƒÎ· Î‘Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿Ï… ÎœÎ¿Î½Ï„Î­Î»Î¿Ï… Î³Î¹Î± Predictions
```python
from model_persistence import load_model
import pandas as pd

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
model_data = load_model('best_model_decision_tree.pkl')
clf = model_data['model']
scaler = model_data['scaler']
label_encoder = model_data['label_encoder']
feature_names = model_data['feature_names']

# Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î½Î­Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
# X_new Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î­Ï‡ÎµÎ¹ Ï„Î¹Ï‚ Î¯Î´Î¹ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ Î¼Îµ Ï„Î¿ training set
X_new = pd.DataFrame(...)  # Î¤Î± Î½Î­Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÏƒÎ±Ï‚

# ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
X_new_scaled = scaler.transform(X_new)

# Î ÏÏŒÎ²Î»ÎµÏˆÎ·
predictions = clf.predict(X_new_scaled)
probabilities = clf.predict_proba(X_new_scaled)

# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ labels
labels = label_encoder.inverse_transform(predictions)

print(f"Predictions: {labels}")
print(f"Probabilities: {probabilities}")
```

---

## ğŸ“ Î”Î¿Î¼Î® Project

```
DrDoS-Detector/
â”œâ”€â”€ train.py                      # ÎšÏÏÎ¹Î¿ script ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
â”œâ”€â”€ data_preprocessing.py         # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· & ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
â”œâ”€â”€ data_balancing.py             # SMOTE implementation
â”œâ”€â”€ data_splitting.py             # Train/Test splitting
â”œâ”€â”€ model_training.py             # Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ (5 models)
â”œâ”€â”€ model_evaluation.py           # Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· & Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚
â”œâ”€â”€ model_comparison.py           # Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
â”œâ”€â”€ model_persistence.py          # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·/Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
â”œâ”€â”€ DrDoS_DNS.csv                 # Dataset (download Î±Ï€ÏŒ releases)
â”œâ”€â”€ README.md                     # Î‘Ï…Ï„ÏŒ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿
â”œâ”€â”€ .gitignore                    # Git exclusions
â”‚
â”œâ”€â”€ training_results_*.txt        # ÎœÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
â”œâ”€â”€ comparison_results_*.txt      # Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ­Ï‚ Î±Î½Î±Î»ÏÏƒÎµÎ¹Ï‚
â”œâ”€â”€ best_model_*.pkl              # Î‘Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î±
â””â”€â”€ drdos_detector_model.pkl      # Single model output
```

---

## ğŸ“¦ Î‘Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚

### Python Packages
```txt
pandas>=1.5.0
numpy>=1.23.0
scikit-learn>=1.2.0
imbalanced-learn>=0.10.0
```

### Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·
```bash
pip install pandas numpy scikit-learn imbalanced-learn
```

### Î£ÏÏƒÏ„Î·Î¼Î±
- Python 3.8+
- RAM: 8GB+ ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹ (Î³Î¹Î± Ï„Î¿ dataset Ï„Ï‰Î½ 5M+ samples)
- CPU: Multi-core Î³Î¹Î± parallel processing

---

## ğŸ“Š Dataset

- **Î‘ÏÏ‡ÎµÎ¯Î¿:** `DrDoS_DNS.csv`
- **Î›Î®ÏˆÎ·:** Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ ÏƒÏ„Î± [GitHub Releases](https://github.com/kulisk/DrDoS-Detector/releases)
- **Samples:** 5,074,413
- **Features:** 88 (Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ 84)
- **Classes:** BENIGN (0.07%), DrDoS_DNS (99.93%)
- **Î‘Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±:** ~1:1,464 ratio

**Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·:** Î›ÏŒÎ³Ï‰ Î¼ÎµÎ³Î­Î¸Î¿Ï…Ï‚, Ï„Î¿ dataset Î´ÎµÎ½ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÏ„Î±Î¹ ÏƒÏ„Î¿ repository. ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ Î±Ï€ÏŒ Ï„Î± releases ÎºÎ±Î¹ Ï„Î¿Ï€Î¿Î¸ÎµÏ„Î®ÏƒÏ„Îµ Ï„Î¿ ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ Ï„Î¿Ï… project.

---

## Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î”Î¹Î±Ï†Î¿ÏÎ­Ï‚ Î±Ï€ÏŒ Î›Î¬Î¸Î¿Ï‚ Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚

### âŒ Î›Î‘Î˜ÎŸÎ£ Approach:
1. Split data â†’ Train/Test
2. Apply SMOTE â†’ Training set ÎœÎŸÎÎŸ
3. **Î ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±:**
   - Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± Î±Ï€ÏŒ Ï„Î¿ test set Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± "Î´Î¹Î±ÏÏÎµÏÏƒÎµÎ¹" ÏƒÏ„Î¿ training
   - Test set Ï€Î±ÏÎ±Î¼Î­Î½ÎµÎ¹ Î±Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿
   - Î‘Î½Î±Î¾Î¹ÏŒÏ€Î¹ÏƒÏ„Î· Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·

### âœ… Î£Î©Î£Î¤ÎŸ Approach (Î±Ï…Ï„ÏŒ Ï„Î¿ project):
1. **Separate classes** â†’ BENIGN & DDoS Î¾ÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„Î¬
2. **Apply SMOTE FIRST** â†’ BENIGN augmentation (3.4K â†’ 33.5K)
3. **Split AFTER SMOTE** â†’ 
   - Test = ALL original BENIGN + equal DDoS
   - Train = SMOTE BENIGN + remaining DDoS
4. **Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±:** 
   - Test set ÎºÎ±Î¸Î±ÏÏŒ (100% original data)
   - Î•Î¾Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î± train & test sets
   - Î‘Î¾Î¹ÏŒÏ€Î¹ÏƒÏ„Î· Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·
   - ÎšÎ±Î¼Î¯Î± data leakage

---

## ğŸ“ Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Îµ Ï„Î¿ Î†ÏÎ¸ÏÎ¿

### Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ Î±Ï€ÏŒ Ï„Î¿ Î†ÏÎ¸ÏÎ¿
- **Logistic Regression** (ÎºÏÏÎ¹Î¿Ï‚ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚)
- Accuracy: ~96-98% (ÏƒÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿)

### Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚
| Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ | Accuracy | Î£Ï‡ÏŒÎ»Î¹Î± |
|-----------|----------|---------|
| **Decision Tree** ğŸ¥‡ | **99.99%** | Î¥Ï€ÎµÏÎ­Ï‡ÎµÎ¹ Ï„Î¿Ï… Î¬ÏÎ¸ÏÎ¿Ï…, Ï„Î±Ï‡ÏÏ„Î±Ï„Î¿Ï‚ |
| **Logistic Regression** | **99.96%** | ÎšÎ±Î»ÏÏ„ÎµÏÎ¿Ï‚ Î±Ï€ÏŒ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿ (~97%) |
| **Random Forest** | **99.94%** | Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ® Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± |

### Î Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î± Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚
âœ… **ÎšÎ±Î»ÏÏ„ÎµÏÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·** Î±Ï€ÏŒ Ï„Î¿ Î¬ÏÎ¸ÏÎ¿ (99.96% vs ~97%)  
âœ… **Î Î¿Î»Î»Î±Ï€Î»Î¿Î¯ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹** Î¼Îµ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·  
âœ… **ÎœÎ­Ï„ÏÎ·ÏƒÎ· Ï‡ÏÏŒÎ½Ï‰Î½** ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚  
âœ… **Î£Ï‰ÏƒÏ„Î® SMOTE ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ®** (Î Î¡Î™Î Ï„Î¿ splitting)  
âœ… **Modular & Extensible** architecture  
âœ… **Production-ready** Î¼Îµ auto-save features  

---

## ğŸ”¬ Î¤ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚

## ğŸ”¬ Î¤ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚

### SMOTE Implementation
- Î§ÏÎ®ÏƒÎ· `imblearn.over_sampling.SMOTE`
- k_neighbors = min(5, len(BENIGN) - 1)
- Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏƒÏ…Î½Î¸ÎµÏ„Î¹ÎºÏÎ½ samples Î¼Îµ interpolation
- Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î Î¡Î™Î Ï„Î¿ splitting Î³Î¹Î± ÏƒÏ‰ÏƒÏ„Î® Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·

### Data Splitting Logic
- Test ratio calculation: `train_size = test_size * (1 - test_ratio) / test_ratio`
- Subsampling SMOTE Î±Î½ Ï‡ÏÎµÎ¹Î±ÏƒÏ„ÎµÎ¯ Î³Î¹Î± Î½Î± Ï„Î±Î¹ÏÎ¹Î¬Î¾ÎµÎ¹ Ï„Î¿ ratio
- Balanced train & test sets (50-50) Î³Î¹Î± Î²Î­Î»Ï„Î¹ÏƒÏ„Î· ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
- Î¤Ï…Ï‡Î±Î¯Î± ÎµÏ€Î¹Î»Î¿Î³Î® DDoS samples Ï‡Ï‰ÏÎ¯Ï‚ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±

### Model Parameters

#### Logistic Regression
```python
LogisticRegression(
    max_iter=1000,
    random_state=42,
    n_jobs=-1,      # Î Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
    verbose=1
)
```

#### Random Forest
```python
RandomForestClassifier(
    n_estimators=100,
    max_depth=30,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1,      # Î Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
    verbose=1
)
```

#### Decision Tree
```python
DecisionTreeClassifier(
    max_depth=30,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42
)
```

#### Support Vector Machine
```python
SVC(
    kernel='rbf',
    C=1.0,
    random_state=42,
    verbose=True
)
```

#### K-Nearest Neighbors
```python
KNeighborsClassifier(
    n_neighbors=5,
    weights='uniform',
    n_jobs=-1       # Î Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
)
```

### Feature Importance Extraction
- **Tree-based models** (RF, DT): `model.feature_importances_`
- **Linear models** (LR, SVM): `np.abs(model.coef_[0])`
- Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Ï„ÏÏ€Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…

### Performance Optimization
- **Parallel Processing**: Î§ÏÎ®ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ CPU cores (n_jobs=-1)
- **Efficient Memory Usage**: Subsampling ÏŒÏ€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
- **Vectorized Operations**: Pandas & NumPy optimizations
- **Reproducibility**: Fixed random_state Î³Î¹Î± consistency

---

## ğŸ› Troubleshooting

### Memory Issues
Î‘Î½ Î±Î½Ï„Î¹Î¼ÎµÏ„Ï‰Ï€Î¯Î¶ÎµÏ„Îµ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± Î¼Î½Î®Î¼Î·Ï‚:
```python
# ÎœÎµÎ¹ÏÏƒÏ„Îµ Ï„Î¿ SMOTE ratio
SMOTE_TARGET_RATIO = 5  # Î‘Î½Ï„Î¯ Î³Î¹Î± 10

# Î‰ Î¼ÎµÎ¹ÏÏƒÏ„Îµ Ï„Î¿ TEST_SIZE
TEST_SIZE = 0.10  # Î‘Î½Ï„Î¯ Î³Î¹Î± 0.20
```

### Slow Training
Î“Î¹Î± Ï„Î±Ï‡ÏÏ„ÎµÏÎ· ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·:
```python
# Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿Ï…Ï‚ Î±ÏÎ³Î¿ÏÏ‚ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…Ï‚
ENABLE_MODELS = {
    'Logistic Regression': False,  # Î‘ÏÎ³ÏŒÏ‚
    'Random Forest': False,
    'SVM': False,                   # Î Î¿Î»Ï Î±ÏÎ³ÏŒÏ‚
    'Decision Tree': True,          # Î¤Î±Ï‡ÏÏ„ÎµÏÎ¿Ï‚
    'KNN': False                    # Î•Î¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ Î±ÏÎ³ÏŒÏ‚
}
```

### Dataset Not Found
```bash
# Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Ï„Î¿ CSV ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿Î½ ÏƒÏ‰ÏƒÏ„ÏŒ Ï†Î¬ÎºÎµÎ»Î¿
ls DrDoS_DNS.csv

# Î‘Î½ ÏŒÏ‡Î¹, ÎºÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Î±Ï€ÏŒ Ï„Î± releases
# ÎºÎ±Î¹ Ï„Î¿Ï€Î¿Î¸ÎµÏ„Î®ÏƒÏ„Îµ Ï„Î¿ ÏƒÏ„Î¿Î½ root Ï†Î¬ÎºÎµÎ»Î¿ Ï„Î¿Ï… project
```

---

## ğŸ“š Î‘Î½Î±Ï†Î¿ÏÎ­Ï‚

### Paper
**"Predicting of DDoS Attack on DNS Server using Machine Learning"**
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯: Logistic Regression
- Dataset: DrDoS DNS Attack traces
- Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±: ~96-98% accuracy

### Î’ÎµÎ»Ï„Î¹ÏÏƒÎµÎ¹Ï‚ Î±Ï…Ï„Î®Ï‚ Ï„Î·Ï‚ Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚
1. âœ… Î¥ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ· accuracy (99.94-99.99%)
2. âœ… Î Î¿Î»Î»Î±Ï€Î»Î¿Î¯ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ Î¼Îµ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·
3. âœ… Î£Ï‰ÏƒÏ„Î® SMOTE implementation (Î Î¡Î™Î splitting)
4. âœ… ÎœÎ­Ï„ÏÎ·ÏƒÎ· Ï‡ÏÏŒÎ½Ï‰Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
5. âœ… Production-ready architecture
6. âœ… Comprehensive documentation

---

## ğŸ¤ Contributing

Contributions are welcome! Î“Î¹Î± Î½Î± ÏƒÏ…Î½ÎµÎ¹ÏƒÏ†Î­ÏÎµÏ„Îµ:

1. Fork Ï„Î¿ repository
2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit Ï„Î¹Ï‚ Î±Î»Î»Î±Î³Î­Ï‚ ÏƒÎ±Ï‚ (`git commit -m 'Add some AmazingFeature'`)
4. Push ÏƒÏ„Î¿ branch (`git push origin feature/AmazingFeature`)
5. Î‘Î½Î¿Î¯Î¾Ï„Îµ Pull Request

---

## ğŸ“„ License

Î‘Ï…Ï„ÏŒ Ï„Î¿ project ÎµÎ¯Î½Î±Î¹ Î±Î½Î¿Î¹Ï‡Ï„Î¿Ï ÎºÏÎ´Î¹ÎºÎ± ÎºÎ±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ Î³Î¹Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ¿ÏÏ‚ ÎºÎ±Î¹ ÎµÏÎµÏ…Î½Î·Ï„Î¹ÎºÎ¿ÏÏ‚ ÏƒÎºÎ¿Ï€Î¿ÏÏ‚.

---

## ğŸ‘¥ Authors

**DrDoS-Detector Team**
- Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· & Implementation
- Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î‘Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½
- Documentation & Testing

---

## ğŸ™ Acknowledgments

- Î¤Î¿ Î¬ÏÎ¸ÏÎ¿ Ï€Î¿Ï… ÎµÎ½Î­Ï€Î½ÎµÏ…ÏƒÎµ Î±Ï…Ï„Î®Î½ Ï„Î·Î½ Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·
- Scikit-learn community Î³Î¹Î± Ï„Î± ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ ML tools
- Imbalanced-learn Î³Î¹Î± Ï„Î¿ SMOTE implementation
- ÎŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ contributors ÎºÎ±Î¹ testers

---

## ğŸ“ Contact & Support

Î“Î¹Î± ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚, issues Î® suggestions:
- ğŸ› [GitHub Issues](https://github.com/kulisk/DrDoS-Detector/issues)
- ğŸ“§ Email: [Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ ÏƒÏ„Î¿ GitHub Profile]
- ğŸ“– [Documentation](https://github.com/kulisk/DrDoS-Detector)

---

**â­ Î‘Î½ ÏƒÎ±Ï‚ Î²Î¿Î®Î¸Î·ÏƒÎµ Î±Ï…Ï„ÏŒ Ï„Î¿ project, Î´ÏÏƒÏ„Îµ Î­Î½Î± star ÏƒÏ„Î¿ GitHub! â­**

"""
ÎŸÎ»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î· Î‘Î½Î¬Î»Ï…ÏƒÎ· DDoS Detection Î¼Îµ Logistic Regression ÎºÎ±Î¹ SMOTE

Î‘Ï…Ï„ÏŒ Ï„Î¿ script ÎµÎºÏ„ÎµÎ»ÎµÎ¯ Ï„Î·Î½ Ï€Î»Î®ÏÎ· Î±Î½Î¬Î»Ï…ÏƒÎ· Î³Î¹Î± Ï„Î·Î½ Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· DDoS ÎµÏ€Î¹Î¸Î­ÏƒÎµÏ‰Î½:
1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
2. ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
3. Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE Î³Î¹Î± Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
4. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Logistic Regression
5. Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÎºÎ±Î¹ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
6. Î‘Î½Î¬Î»Ï…ÏƒÎ· ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½

Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏÎµÏ„Î±Î¹ ÎœÎŸÎÎŸ Î¼Îµ SMOTE-balanced Î´ÎµÎ´Î¿Î¼Î­Î½Î±.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
import warnings
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report, 
    confusion_matrix, 
    accuracy_score,
    precision_score, 
    recall_score, 
    f1_score,
    roc_curve,
    auc
)

# Î‘Ï€ÏŒÎºÏÏ…ÏˆÎ· warnings
warnings.filterwarnings('ignore')

# Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚
sns.set_palette("husl")
plt.style.use('seaborn-v0_8-whitegrid')
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

# ============================================================================
# Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ•Î£ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î•Î™Î£
# ============================================================================

def print_header(title, char="="):
    """Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· ÏŒÎ¼Î¿ÏÏ†Î¿Ï… header"""
    print(f"\n{char*70}")
    print(f" {title}")
    print(f"{char*70}\n")

def print_section(title):
    """Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Ï„Î¯Ï„Î»Î¿Ï… section"""
    print(f"\n{'='*70}")
    print(f"{title}")
    print(f"{'='*70}\n")

def save_figure(fig, filename, results_dir='results', dpi=150):
    """Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚"""
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    filepath = os.path.join(results_dir, filename)
    fig.savefig(filepath, dpi=dpi, bbox_inches='tight')
    plt.close(fig)
    print(f"âœ“ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ: {filepath}")

# ============================================================================
# 1. Î¦ÎŸÎ¡Î¤Î©Î£Î— ÎšÎ‘Î™ Î Î¡ÎŸÎ•Î Î•ÎÎ•Î¡Î“Î‘Î£Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î
# ============================================================================

def load_and_preprocess_data(csv_file='DrDoS_DNS.csv'):
    """
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    
    Args:
        csv_file: Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ CSV Î¼Îµ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
        
    Returns:
        X: Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
        y: Labels
        feature_names: ÎŸÎ½ÏŒÎ¼Î±Ï„Î± Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
        df: Original dataframe Î³Î¹Î± visualizations
    """
    print_section("Î¦ÎŸÎ¡Î¤Î©Î£Î— ÎšÎ‘Î™ Î Î¡ÎŸÎ•Î Î•ÎÎ•Î¡Î“Î‘Î£Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    print("ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
    df = pd.read_csv(csv_file)
    print(f"âœ“ Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(df):,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚")
    
    # Î•Ï€Î¹Î»Î¿Î³Î® Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns
    features = [col for col in numeric_features if col != ' Label']
    X = df[features]
    y = df[' Label']
    
    print(f"\nğŸ“Š Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ Dataset:")
    print(f"   - Î•Î³Î³ÏÎ±Ï†Î­Ï‚: {X.shape[0]:,}")
    print(f"   - Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬: {X.shape[1]}")
    
    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    print("\nğŸ”„ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
    X = X.replace([np.inf, -np.inf], np.nan)
    original_len = len(X)
    mask = X.notna().all(axis=1)
    X = X[mask]
    y = y[mask]
    df = df[mask].reset_index(drop=True)
    removed_rows = original_len - len(X)
    
    print(f"âœ“ Î‘Ï†Î±Î¹ÏÎ­Î¸Î·ÎºÎ±Î½ {removed_rows:,} Î³ÏÎ±Î¼Î¼Î­Ï‚ Î¼Îµ ÎµÎ»Î»Î¹Ï€ÎµÎ¯Ï‚ Ï„Î¹Î¼Î­Ï‚")
    print(f"âœ“ Î¤ÎµÎ»Î¹ÎºÏŒ Î¼Î­Î³ÎµÎ¸Î¿Ï‚: {len(X):,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚")
    
    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® labels ÏƒÎµ binary
    y = (y == 'DrDoS_DNS').astype(int)
    
    # ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½
    value_counts = y.value_counts()
    print("\nğŸ“ˆ ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½ (Î Î¡Î™Î Ï„Î¿ SMOTE):")
    for label, count in value_counts.items():
        percentage = count / len(y) * 100
        class_name = 'Attack' if label == 1 else 'Normal'
        print(f"   - {class_name}: {count:,} ({percentage:.2f}%)")
    
    return X, y, X.columns.tolist(), df

# ============================================================================
# 2. ÎŸÎ Î¤Î™ÎšÎŸÎ ÎŸÎ™Î—Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î
# ============================================================================

def visualize_data(X, y, df, results_dir='results'):
    """
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    
    Args:
        X: Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
        y: Labels
        df: Original dataframe
        results_dir: Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚
    """
    print_section("ÎŸÎ Î¤Î™ÎšÎŸÎ ÎŸÎ™Î—Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    
    # 1. Î§Î¬ÏÏ„Î·Ï‚ ÏƒÏ…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚
    print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï‡Î¬ÏÏ„Î· ÏƒÏ…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚...")
    fig, ax = plt.subplots(figsize=(20, 16))
    correlation_matrix = X.corr()
    sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, ax=ax)
    ax.set_title('Î§Î¬ÏÏ„Î·Ï‚ Î£Ï…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½', fontsize=16, fontweight='bold')
    save_figure(fig, 'correlation_matrix.png', results_dir)
    
    # 2. ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½
    print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± pie chart ÎºÎ»Î¬ÏƒÎµÏ‰Î½...")
    fig, ax = plt.subplots(figsize=(10, 8))
    value_counts = y.value_counts()
    attack_count = value_counts.get(1, 0)
    normal_count = value_counts.get(0, 0)
    
    sizes = [attack_count, normal_count]
    labels_pie = ['Attack', 'Normal']
    colors = ['#ff9999', '#66b3ff']
    
    ax.pie(sizes, labels=labels_pie, autopct='%1.1f%%', colors=colors, 
           startangle=90, textprops={'fontsize': 14})
    ax.set_title('ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎšÎ»Î¬ÏƒÎµÏ‰Î½ (Î ÏÎ¹Î½ SMOTE)', fontsize=16, fontweight='bold')
    save_figure(fig, 'class_distribution_before_smote.png', results_dir)
    
    # 3. Box plots Î³Î¹Î± top Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
    print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± box plots...")
    top_features = [' Source Port', ' Protocol', ' Flow Duration', 
                   ' Total Fwd Packets', ' Total Length of Bwd Packets']
    
    available_features = [f for f in top_features if f in df.columns]
    
    if available_features:
        n_features = len(available_features)
        n_cols = min(3, n_features)
        n_rows = (n_features + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))
        if n_features == 1:
            axes = [axes]
        else:
            axes = axes.ravel() if n_features > 1 else [axes]
        
        for i, feature in enumerate(available_features):
            if i < len(axes):
                sns.boxplot(data=df, x=' Label', y=feature, ax=axes[i])
                axes[i].set_title(f'Distribution of {feature}', fontsize=12)
        
        # Î‘Ï€ÏŒÎºÏÏ…ÏˆÎ· ÎºÎµÎ½ÏÎ½ subplots
        for i in range(n_features, len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        save_figure(fig, 'top_features_distribution.png', results_dir)

# ============================================================================
# 3. Î§Î©Î¡Î™Î£ÎœÎŸÎ£ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î ÎšÎ‘Î™ ÎšÎ‘ÎÎŸÎÎ™ÎšÎŸÎ ÎŸÎ™Î—Î£Î—
# ============================================================================

def prepare_train_test_data(X, y):
    """
    Î§Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Ï„Î± ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯
    
    Returns:
        scaler, X_train, X_test, y_train, y_test
    """
    print_section("Î§Î©Î¡Î™Î£ÎœÎŸÎ£ ÎšÎ‘Î™ ÎšÎ‘ÎÎŸÎÎ™ÎšÎŸÎ ÎŸÎ™Î—Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    
    # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    print("ğŸ”„ ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ train/test
    print("ğŸ”„ Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎµ train/test sets...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"   Train set: {X_train.shape[0]:,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚")
    print(f"   Test set: {X_test.shape[0]:,} ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚")
    
    return scaler, X_train, X_test, y_train, y_test

# ============================================================================
# 4. Î•Î¦Î‘Î¡ÎœÎŸÎ“Î— SMOTE
# ============================================================================

def apply_smote(X_train, y_train, results_dir='results'):
    """
    Î•Ï†Î±ÏÎ¼ÏŒÎ¶ÎµÎ¹ SMOTE Î³Î¹Î± Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    
    Returns:
        X_train_balanced, y_train_balanced
    """
    print_section("Î•Î¦Î‘Î¡ÎœÎŸÎ“Î— SMOTE Î“Î™Î‘ Î™Î£ÎŸÎ¡Î¡ÎŸÎ Î™Î‘ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
    
    # Import SMOTE
    try:
        from imblearn.over_sampling import SMOTE
    except ImportError:
        print("âš ï¸ Î•Î³ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· imbalanced-learn...")
        import subprocess
        subprocess.check_call(['pip', 'install', 'imbalanced-learn'])
        from imblearn.over_sampling import SMOTE
    
    # Î‘ÏÏ‡Î¹ÎºÎ® ÎºÎ±Ï„Î±Î½Î¿Î¼Î®
    print("ğŸ“Š Î‘ÏÏ‡Î¹ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® (Training Set):")
    print(f"   Normal (0): {sum(y_train == 0):,} ({sum(y_train == 0)/len(y_train)*100:.2f}%)")
    print(f"   Attack (1): {sum(y_train == 1):,} ({sum(y_train == 1)/len(y_train)*100:.2f}%)")
    print(f"   Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬: {len(y_train):,}")
    
    # Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE
    print("\nâš™ï¸ Î•Ï†Î±ÏÎ¼Î¿Î³Î® SMOTE (ÏƒÏ„ÏŒÏ‡Î¿Ï‚: 50-50 Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±)...")
    smote = SMOTE(sampling_strategy=1.0, random_state=42, k_neighbors=5)
    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
    
    # ÎÎ­Î± ÎºÎ±Ï„Î±Î½Î¿Î¼Î®
    print("\nâœ… ÎÎ­Î± ÎšÎ±Ï„Î±Î½Î¿Î¼Î® (Î¼ÎµÏ„Î¬ Ï„Î¿ SMOTE):")
    print(f"   Normal (0): {sum(y_train_balanced == 0):,} ({sum(y_train_balanced == 0)/len(y_train_balanced)*100:.2f}%)")
    print(f"   Attack (1): {sum(y_train_balanced == 1):,} ({sum(y_train_balanced == 1)/len(y_train_balanced)*100:.2f}%)")
    print(f"   Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬: {len(y_train_balanced):,}")
    
    # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
    normal_increase = sum(y_train_balanced == 0) - sum(y_train == 0)
    print(f"\nğŸ“ˆ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ SMOTE:")
    print(f"   Î£Ï…Î½Î¸ÎµÏ„Î¹ÎºÎ¬ Normal samples: {normal_increase:,}")
    print(f"   Î‘ÏÎ¾Î·ÏƒÎ·: {(normal_increase / sum(y_train == 0)):.1f}x")
    
    # ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    print("\nğŸ“Š ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î±Ï‚...")
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Î ÏÎ¹Î½ SMOTE
    sizes_before = [sum(y_train == 0), sum(y_train == 1)]
    labels_pie = ['Normal', 'Attack']
    colors = ['#66b3ff', '#ff9999']
    
    axes[0].pie(sizes_before, labels=labels_pie, autopct='%1.1f%%',
                colors=colors, startangle=90, textprops={'fontsize': 12})
    axes[0].set_title('Î ÏÎ¹Î½ Ï„Î¿ SMOTE\n(Î‘Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿)', 
                     fontsize=14, fontweight='bold')
    
    # ÎœÎµÏ„Î¬ SMOTE
    sizes_after = [sum(y_train_balanced == 0), sum(y_train_balanced == 1)]
    axes[1].pie(sizes_after, labels=labels_pie, autopct='%1.1f%%',
                colors=colors, startangle=90, textprops={'fontsize': 12})
    axes[1].set_title('ÎœÎµÏ„Î¬ Ï„Î¿ SMOTE\n(Î™ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿ 50-50)', 
                     fontsize=14, fontweight='bold')
    
    save_figure(fig, 'smote_balance_comparison.png', results_dir)
    
    return X_train_balanced, y_train_balanced

# ============================================================================
# 5. Î•ÎšÎ Î‘Î™Î”Î•Î¥Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥
# ============================================================================

def train_model(X_train_balanced, y_train_balanced, scaler, feature_names):
    """
    Î•ÎºÏ€Î±Î¹Î´ÎµÏÎµÎ¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î¼Îµ balanced Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    
    Returns:
        model: Î¤Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿
    """
    print_section("Î•ÎšÎ Î‘Î™Î”Î•Î¥Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥ LOGISTIC REGRESSION")
    
    print("ğŸ”§ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Î¼Îµ SMOTE-balanced Î´ÎµÎ´Î¿Î¼Î­Î½Î±...")
    model = LogisticRegression(random_state=42, max_iter=1000, verbose=0)
    model.fit(X_train_balanced, y_train_balanced)
    print("âœ“ Î— ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!")
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    print("\nğŸ’¾ Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…...")
    model_dir = 'trained_model'
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
    
    joblib.dump(model, f'{model_dir}/logistic_regression_model.joblib')
    joblib.dump(scaler, f'{model_dir}/scaler.joblib')
    pd.Series(feature_names).to_csv(f'{model_dir}/feature_names.csv', index=False)
    
    print(f"âœ“ ÎœÎ¿Î½Ï„Î­Î»Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÏƒÏ„Î¿ '{model_dir}/'")
    print(f"  - logistic_regression_model.joblib")
    print(f"  - scaler.joblib")
    print(f"  - feature_names.csv")
    
    return model

# ============================================================================
# 6. Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥
# ============================================================================

def evaluate_model(model, X_test, y_test, results_dir='results'):
    """
    Î‘Î¾Î¹Î¿Î»Î¿Î³ÎµÎ¯ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿
    """
    print_section("Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î— ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥")
    
    # Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚
    print("ğŸ” Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½...")
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # Classification Report
    print("\nğŸ“Š Classification Report:")
    print("-" * 70)
    print(classification_report(y_test, y_pred,
                              target_names=['Normal Traffic', 'Attack Traffic']))
    
    # ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚
    accuracy = accuracy_score(y_test, y_pred)
    precision_normal = precision_score(y_test, y_pred, pos_label=0, zero_division=0)
    recall_normal = recall_score(y_test, y_pred, pos_label=0, zero_division=0)
    f1_normal = f1_score(y_test, y_pred, pos_label=0, zero_division=0)
    precision_attack = precision_score(y_test, y_pred, pos_label=1, zero_division=0)
    recall_attack = recall_score(y_test, y_pred, pos_label=1, zero_division=0)
    f1_attack = f1_score(y_test, y_pred, pos_label=1, zero_division=0)
    
    # Î£ÏÎ½Î¿ÏˆÎ· Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½
    print("\nğŸ“Š Î£ÏÎ½Î¿ÏˆÎ· ÎœÎµÏ„ÏÎ¹ÎºÏÎ½:")
    print(f"   Overall Accuracy: {accuracy:.4f}")
    print(f"\n   Normal Traffic:")
    print(f"     - Precision: {precision_normal:.4f}")
    print(f"     - Recall: {recall_normal:.4f}")
    print(f"     - F1-Score: {f1_normal:.4f}")
    print(f"\n   Attack Traffic:")
    print(f"     - Precision: {precision_attack:.4f}")
    print(f"     - Recall: {recall_attack:.4f}")
    print(f"     - F1-Score: {f1_attack:.4f}")
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½
    metrics_df = pd.DataFrame({
        'Metric': ['Accuracy', 'Normal Precision', 'Normal Recall', 'Normal F1',
                   'Attack Precision', 'Attack Recall', 'Attack F1'],
        'Score': [accuracy, precision_normal, recall_normal, f1_normal,
                  precision_attack, recall_attack, f1_attack]
    })
    metrics_df.to_csv(f'{results_dir}/model_metrics.csv', index=False)
    print(f"\nâœ“ ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿ '{results_dir}/model_metrics.csv'")
    
    # Confusion Matrix
    print("\nğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Confusion Matrix...")
    fig, ax = plt.subplots(figsize=(10, 8))
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, 
                xticklabels=['Normal', 'Attack'],
                yticklabels=['Normal', 'Attack'])
    ax.set_title('Confusion Matrix', fontsize=16, fontweight='bold')
    ax.set_ylabel('True Label', fontsize=12)
    ax.set_xlabel('Predicted Label', fontsize=12)
    save_figure(fig, 'confusion_matrix.png', results_dir)
    
    # ROC Curve
    print("ğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ROC Curve...")
    fig, ax = plt.subplots(figsize=(10, 8))
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)
    
    ax.plot(fpr, tpr, color='darkorange', lw=2, 
            label=f'ROC curve (AUC = {roc_auc:.4f})')
    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('False Positive Rate', fontsize=12)
    ax.set_ylabel('True Positive Rate', fontsize=12)
    ax.set_title('ROC Curve', fontsize=16, fontweight='bold')
    ax.legend(loc="lower right")
    ax.grid(alpha=0.3)
    save_figure(fig, 'roc_curve.png', results_dir)
    
    return {
        'accuracy': accuracy,
        'precision_normal': precision_normal,
        'recall_normal': recall_normal,
        'f1_normal': f1_normal,
        'precision_attack': precision_attack,
        'recall_attack': recall_attack,
        'f1_attack': f1_attack,
        'roc_auc': roc_auc
    }

# ============================================================================
# 7. Î‘ÎÎ‘Î›Î¥Î£Î— Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸÎ¤Î—Î¤Î‘Î£ Î§Î‘Î¡Î‘ÎšÎ¤Î—Î¡Î™Î£Î¤Î™ÎšÎ©Î
# ============================================================================

def analyze_feature_importance(model, feature_names, results_dir='results'):
    """
    Î‘Î½Î±Î»ÏÎµÎ¹ Ï„Î· ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î± Ï„Ï‰Î½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
    """
    print_section("Î‘ÎÎ‘Î›Î¥Î£Î— Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸÎ¤Î—Î¤Î‘Î£ Î§Î‘Î¡Î‘ÎšÎ¤Î—Î¡Î™Î£Î¤Î™ÎšÎ©Î")
    
    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': abs(model.coef_[0]),
        'coefficient': model.coef_[0]
    })
    feature_importance = feature_importance.sort_values('importance', ascending=False)
    
    # Top 15
    print("ğŸ“Š Top 15 Î£Î·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„ÎµÏÎ± Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬:")
    print("-" * 70)
    for idx, row in feature_importance.head(15).iterrows():
        sign = '+' if row['coefficient'] > 0 else '-'
        print(f"{row['feature']:50} {row['importance']:.6f} ({sign})")
    
    # ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
    print("\nğŸ“Š Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î¿Ï‚ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚...")
    fig, ax = plt.subplots(figsize=(12, 10))
    top_features = feature_importance.head(20)
    
    colors = ['#ff9999' if c < 0 else '#99ff99' for c in top_features['coefficient']]
    sns.barplot(data=top_features, x='importance', y='feature', palette=colors, ax=ax)
    
    ax.set_title('Top 20 Most Important Features', fontsize=16, fontweight='bold')
    ax.set_xlabel('Absolute Coefficient Value', fontsize=12)
    ax.set_ylabel('Feature', fontsize=12)
    ax.grid(axis='x', alpha=0.3)
    
    save_figure(fig, 'feature_importance.png', results_dir)
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·
    feature_importance.to_csv(f'{results_dir}/feature_importance.csv', index=False)
    print(f"âœ“ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ: {results_dir}/feature_importance.csv")
    
    return feature_importance

# ============================================================================
# 8. Î¤Î•Î›Î™ÎšÎ— Î£Î¥ÎÎŸÎ¨Î—
# ============================================================================

def print_summary(metrics):
    """
    Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Ï„ÎµÎ»Î¹ÎºÎ®Ï‚ ÏƒÏÎ½Î¿ÏˆÎ·Ï‚
    """
    print_section("Î¤Î•Î›Î™ÎšÎ— Î£Î¥ÎÎŸÎ¨Î— Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î")
    
    print("ğŸ“Œ Î’Î±ÏƒÎ¹ÎºÎ¬ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±:\n")
    
    print(f"1. Î£Î¥ÎÎŸÎ›Î™ÎšÎ— Î‘Î ÎŸÎ”ÎŸÎ£Î—:")
    print(f"   âœ“ Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
    print(f"   âœ“ ROC AUC: {metrics['roc_auc']:.4f}")
    
    print(f"\n2. NORMAL TRAFFIC DETECTION:")
    print(f"   âœ“ Precision: {metrics['precision_normal']:.4f}")
    print(f"   âœ“ Recall: {metrics['recall_normal']:.4f}")
    print(f"   âœ“ F1-Score: {metrics['f1_normal']:.4f}")
    
    print(f"\n3. ATTACK TRAFFIC DETECTION:")
    print(f"   âœ“ Precision: {metrics['precision_attack']:.4f}")
    print(f"   âœ“ Recall: {metrics['recall_attack']:.4f}")
    print(f"   âœ“ F1-Score: {metrics['f1_attack']:.4f}")
    
    print("\n4. Î§Î‘Î¡Î‘ÎšÎ¤Î—Î¡Î™Î£Î¤Î™ÎšÎ‘ ÎœÎŸÎÎ¤Î•Î›ÎŸÎ¥:")
    print("   âœ“ Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î¿ Î¼Îµ SMOTE-balanced Î´ÎµÎ´Î¿Î¼Î­Î½Î± (50-50)")
    print("   âœ“ Logistic Regression Î¼Îµ ÏŒÎ»Î± Ï„Î± Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± features")
    print("   âœ“ ÎšÎ±Ï„Î¬Î»Î»Î·Î»Î¿ Î³Î¹Î± Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· DDoS ÎµÏ€Î¹Î¸Î­ÏƒÎµÏ‰Î½ ÏƒÎµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÏŒ Ï‡ÏÏŒÎ½Î¿")
    
    print("\n5. Î‘Î ÎŸÎ˜Î—ÎšÎ•Î¥ÎœÎ•ÎÎ‘ Î‘Î¡Î§Î•Î™Î‘:")
    print("   âœ“ ÎœÎ¿Î½Ï„Î­Î»Î¿: trained_model/")
    print("   âœ“ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±: results/")
    print("   âœ“ Î“ÏÎ±Ï†Î®Î¼Î±Ï„Î±: PNG files ÏƒÏ„Î¿ results/")

# ============================================================================
# ÎšÎ¥Î¡Î™Î‘ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î—
# ============================================================================

def main():
    """
    ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï€Î¿Ï… ÎµÎºÏ„ÎµÎ»ÎµÎ¯ ÏŒÎ»Î· Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·
    """
    print_header("DDOS DETECTION - LOGISTIC REGRESSION ÎœÎ• SMOTE", "=")
    print("Î‘Ï…Ï„ÏŒ Ï„Î¿ script ÎµÎºÏ„ÎµÎ»ÎµÎ¯ Ï„Î·Î½ Ï€Î»Î®ÏÎ· Î±Î½Î¬Î»Ï…ÏƒÎ· Î³Î¹Î± Ï„Î·Î½ Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· DDoS ÎµÏ€Î¹Î¸Î­ÏƒÎµÏ‰Î½")
    print("Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Logistic Regression Î¼Îµ SMOTE-balanced Î´ÎµÎ´Î¿Î¼Î­Î½Î±.\n")
    
    try:
        # 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
        X, y, feature_names, df = load_and_preprocess_data()
        
        # 2. ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
        visualize_data(X, y, df)
        
        # 3. Î§Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
        scaler, X_train, X_test, y_train, y_test = prepare_train_test_data(X, y)
        
        # 4. SMOTE
        X_train_balanced, y_train_balanced = apply_smote(X_train, y_train)
        
        # 5. Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
        model = train_model(X_train_balanced, y_train_balanced, scaler, feature_names)
        
        # 6. Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·
        metrics = evaluate_model(model, X_test, y_test)
        
        # 7. Î‘Î½Î¬Î»Ï…ÏƒÎ· Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
        feature_importance = analyze_feature_importance(model, feature_names)
        
        # 8. Î£ÏÎ½Î¿ÏˆÎ·
        print_summary(metrics)
        
        print_header("ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ• Î•Î Î™Î¤Î¥Î§Î©Î£!", "=")
        print("âœ… Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎºÏ€Î±Î¹Î´ÎµÏÏ„Î·ÎºÎµ ÎºÎ±Î¹ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚")
        print("âœ… ÎŒÎ»Î± Ï„Î± Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ ÎºÎ±Î¹ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½")
        print("âœ… Î¤Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ 'results/'")
        print("âœ… Î¤Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ 'trained_model/'")
        
    except Exception as e:
        print(f"\nâŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

# ============================================================================
# Î•ÎšÎ¤Î•Î›Î•Î£Î—
# ============================================================================

if __name__ == "__main__":
    exit(main())
